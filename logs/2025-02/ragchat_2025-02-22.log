[2025-02-22 21:58:22] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 21:58:42] INFO [RAGChat.agent_excute:73] 1,开始调用llms
[2025-02-22 21:59:44] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 21:59:58] INFO [RAGChat.agent_excute:73] 1,开始调用llms
[2025-02-22 22:00:07] INFO [RAGChat.agent_excute:78] 1,结束调用llms，共耗时8.381254434585571
[2025-02-22 22:00:07] ERROR [RAGChat.agent_excute:81] 调用结果出错，结果如：{
    "action": {
        "name": "online_search",
        "args": {
            "query": "deepseek-r1 版本数量"
        }
    },
    "thoughts": {
        "plan": "通过网络搜索查询deepseek-r1的版本数量，因为当前没有足够的信息来直接回答这个问题。",
        "criticism": "在执行搜索之前，应该先检查是否可以通过已有的知识库来回答问题，以减少资源消耗。但在这个特定情况下，我需要确切的信息，这可能不在我的训练数据中。",
        "speak": "正在查找有关deepseek-r1有多少个版本的信息。",
        "reasoning": "由于我不能确定deepseek-r1的确切版本数量，最有效的方法是使用在线搜索工具来获取最新和准确的信息。"
    },
    "observation": "任务开始，正在寻找关于deepseek-r1版本数量的具体信息。"
},即将重试
[2025-02-22 22:00:07] INFO [RAGChat.agent_excute:73] 2,开始调用llms
[2025-02-22 22:00:17] INFO [RAGChat.agent_excute:78] 2,结束调用llms，共耗时10.323853969573975
[2025-02-22 22:00:17] ERROR [RAGChat.agent_excute:81] 调用结果出错，结果如：{
    "action": {
        "name": "online_search",
        "args": {
            "query": "deepseek-r1 版本数量"
        }
    },
    "thoughts": {
        "plan": "首先，我需要在网络上搜索deepseek-r1的版本信息。然后，根据找到的信息回答用户的问题。",
        "criticism": "在这个阶段，我只能通过网络搜索来获取信息，因为我没有其他途径了解deepseek-r1的具体版本数量。",
        "speak": "让我查询一下deepseek-r1有多少个版本。",
        "reasoning": "由于我对deepseek-r1的版本数量并不确定，因此需要使用online_search动作来获取相关信息。"
    },
    "observation": "任务刚开始，正在查找deepseek-r1的版本数量。"
},即将重试
[2025-02-22 22:00:17] INFO [RAGChat.agent_excute:73] 3,开始调用llms
[2025-02-22 22:00:23] INFO [RAGChat.agent_excute:78] 3,结束调用llms，共耗时6.333678722381592
[2025-02-22 22:00:23] ERROR [RAGChat.agent_excute:81] 调用结果出错，结果如：{
    "action": {
        "name": "online_search",
        "args": {
            "query": "deepseek-r1 版本数量"
        }
    },
    "thoughts": {
        "plan": "首先通过网络搜索获取deepseek-r1的版本信息。根据搜索结果，回答用户的问题。",
        "criticism": "在搜索之前没有更多的背景信息，这可能会导致搜索结果不准确，但是这是目前能采取的最佳行动。",
        "speak": "正在查找deepseek-r1的版本信息。",
        "reasoning": "由于我不能确定deepseek-r1的确切版本数量，因此需要通过网络搜索来获取这些信息。"
    },
    "observation": "任务刚开始，正在收集必要的信息以回答用户的问题。"
},即将重试
[2025-02-22 22:00:23] INFO [RAGChat.agent_excute:73] 4,开始调用llms
[2025-02-22 22:00:32] INFO [RAGChat.agent_excute:78] 4,结束调用llms，共耗时9.000472068786621
[2025-02-22 22:00:32] ERROR [RAGChat.agent_excute:81] 调用结果出错，结果如：{
    "action": {
        "name": "online_search",
        "args": {
            "query": "deepseek-r1 版本数量"
        }
    },
    "thoughts": {
        "plan": "首先，我需要在网络上搜索有关deepseek-r1版本的信息。然后根据搜索结果来确定deepseek-r1有多少个版本。",
        "criticism": "在进行搜索之前，我不能确定能否找到确切的答案。但是这是获取信息最直接的方法。",
        "speak": "我将在网络上搜索deepseek-r1的版本信息。",
        "reasoning": "由于我对deepseek-r1的具体版本信息并不了解，所以我选择使用online_search动作来获取相关信息。"
    },
    "observation": "任务刚开始，正在通过网络搜索获取deepseek-r1版本的相关信息。"
},即将重试
[2025-02-22 22:00:32] INFO [RAGChat.agent_excute:73] 5,开始调用llms
[2025-02-22 22:00:40] INFO [RAGChat.agent_excute:78] 5,结束调用llms，共耗时7.760332822799683
[2025-02-22 22:00:40] ERROR [RAGChat.agent_excute:81] 调用结果出错，结果如：{
    "action": {
        "name": "online_search",
        "args": {
            "query": "deepseek-r1 版本数量"
        }
    },
    "thoughts": {
        "plan": "首先，我需要在网络上搜索有关deepseek-r1版本数量的信息。然后根据找到的信息回答用户的问题。",
        "criticism": "无",
        "speak": "正在查询deepseek-r1的版本数量，请稍等。",
        "reasoning": "通过网络搜索，我可以找到关于deepseek-r1版本数量的相关信息，从而准确地回答用户的问题。"
    },
    "observation": "任务刚开始，正在获取必要的信息以完成任务。"
},即将重试
[2025-02-22 22:00:40] INFO [RAGChat.agent_excute:73] 6,开始调用llms
[2025-02-22 22:00:46] INFO [RAGChat.agent_excute:78] 6,结束调用llms，共耗时6.355438947677612
[2025-02-22 22:00:46] ERROR [RAGChat.agent_excute:81] 调用结果出错，结果如：{
    "action": {
        "name": "online_search",
        "args": {
            "query": "deepseek-r1 版本数量"
        }
    },
    "thoughts": {
        "plan": "首先，我需要在网络上搜索deepseek-r1的版本信息。然后根据搜索结果回答问题。",
        "criticism": "无",
        "speak": "正在查询deepseek-r1的版本信息。",
        "reasoning": "我选择使用online_search动作，因为这个问题的答案可能已经在互联网上存在，通过搜索引擎可以快速找到答案。"
    },
    "observation": "任务刚开始，正在获取必要的信息以完成任务。"
},即将重试
[2025-02-22 22:00:46] INFO [RAGChat.agent_excute:73] 7,开始调用llms
[2025-02-22 22:00:52] INFO [RAGChat.agent_excute:78] 7,结束调用llms，共耗时5.921138763427734
[2025-02-22 22:00:52] ERROR [RAGChat.agent_excute:81] 调用结果出错，结果如：{
    "action": {
        "name": "online_search",
        "args": {
            "query": "deepseek-r1 版本数量"
        }
    },
    "thoughts": {
        "plan": "首先，我需要在网络上搜索有关deepseek-r1版本的信息。然后根据搜索结果回答问题。",
        "criticism": "无",
        "speak": "正在查找deepseek-r1的版本信息。",
        "reasoning": "通过网络搜索，我可以找到关于deepseek-r1版本的相关信息，从而准确地回答问题。"
    },
    "observation": "任务刚开始，正在获取所需信息。"
},即将重试
[2025-02-22 22:00:52] INFO [RAGChat.agent_excute:73] 8,开始调用llms
[2025-02-22 22:01:00] INFO [RAGChat.agent_excute:78] 8,结束调用llms，共耗时7.331763505935669
[2025-02-22 22:01:00] ERROR [RAGChat.agent_excute:81] 调用结果出错，结果如：{
    "action": {
        "name": "online_search",
        "args": {
            "query": "deepseek-r1 版本数量"
        }
    },
    "thoughts": {
        "plan": "通过在线搜索查询deepseek-r1的版本信息，以获取准确的数量。",
        "criticism": "在进行搜索之前，我应该先检查是否可以从已有的知识中找到答案。然而，在这种情况下，直接搜索可能是最快的方法。",
        "speak": "正在查询deepseek-r1有多少个版本的信息。",
        "reasoning": "由于我对deepseek-r1的具体版本信息并不确定，因此选择使用online_search动作来获取最准确的信息。"
    },
    "observation": "任务刚开始，需要通过搜索获取关于deepseek-r1版本数量的信息。"
},即将重试
[2025-02-22 22:01:00] INFO [RAGChat.agent_excute:73] 9,开始调用llms
[2025-02-22 22:01:09] INFO [RAGChat.agent_excute:78] 9,结束调用llms，共耗时8.976483821868896
[2025-02-22 22:01:09] ERROR [RAGChat.agent_excute:81] 调用结果出错，结果如：{
    "action": {
        "name": "online_search",
        "args": {
            "query": "deepseek-r1 版本数量"
        }
    },
    "thoughts": {
        "plan": "首先，我需要在网络上搜索有关deepseek-r1的版本信息。然后，根据找到的信息回答用户的问题。",
        "criticism": "在这个阶段，我不能确定网络上一定能找到准确的答案，但这是获取所需信息最直接的方法。",
        "speak": "正在查询deepseek-r1的版本信息，请稍等。",
        "reasoning": "由于我对deepseek-r1的具体版本数量没有预先的知识，所以选择使用online_search动作来获取最新和准确的信息。"
    },
    "observation": "任务刚开始，正在收集必要的信息以回答用户的问题。"
},即将重试
[2025-02-22 22:01:09] INFO [RAGChat.agent_excute:73] 10,开始调用llms
[2025-02-22 22:01:15] INFO [RAGChat.agent_excute:78] 10,结束调用llms，共耗时6.12543511390686
[2025-02-22 22:01:15] ERROR [RAGChat.agent_excute:81] 调用结果出错，结果如：{
    "action": {
        "name": "online_search",
        "args": {
            "query": "deepseek-r1 版本数量"
        }
    },
    "thoughts": {
        "plan": "首先，我需要在网络上搜索有关deepseek-r1的版本信息。根据搜索结果，我会向用户提供准确的答案。",
        "criticism": "无",
        "speak": "让我查询一下关于deepseek-r1的版本信息。",
        "reasoning": "我选择进行网络搜索，因为我需要收集有关deepseek-r1版本数量的信息。这是获取此类信息最直接的方法。"
    },
    "observation": "任务刚开始，正在搜索相关信息。"
},即将重试
[2025-02-22 22:01:15] INFO [RAGChat.agent_excute:73] 11,开始调用llms
[2025-02-22 22:03:49] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:04:01] INFO [RAGChat.agent_excute:73] 1,开始调用llms
[2025-02-22 22:04:10] INFO [RAGChat.agent_excute:78] 1,结束调用llms，共耗时8.805159091949463
[2025-02-22 22:04:58] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:05:11] INFO [RAGChat.agent_excute:73] 1,开始调用llms
[2025-02-22 22:05:18] INFO [RAGChat.agent_excute:78] 1,结束调用llms，共耗时7.723596096038818
[2025-02-22 22:05:18] ERROR [RAGChat.agent_excute:122] agent action call error: None argument after ** must be a mapping, not NoneType
[2025-02-22 22:06:43] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:06:59] INFO [RAGChat.agent_excute:73] 1,开始调用llms
[2025-02-22 22:07:09] INFO [RAGChat.agent_excute:78] 1,结束调用llms，共耗时9.525346517562866
[2025-02-22 22:07:09] ERROR [RAGChat.agent_excute:122] agent action call error: 1 validation error for TavilySearchAPIWrapper
  Value error, Did not find tavily_api_key, please add an environment variable `TAVILY_API_KEY` which contains it, or pass `tavily_api_key` as a named parameter. [type=value_error, input_value={}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/value_error
[2025-02-22 22:14:57] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:17:21] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:17:30] INFO [RAGChat.agent_excute:73] 1,开始调用llms
[2025-02-22 22:17:38] INFO [RAGChat.agent_excute:78] 1,结束调用llms，共耗时8.719370365142822
[2025-02-22 22:17:38] ERROR [RAGChat.agent_excute:122] agent action call error: 1 validation error for TavilySearchAPIWrapper
  Value error, Did not find tavily_api_key, please add an environment variable `TAVILY_API_KEY` which contains it, or pass `tavily_api_key` as a named parameter. [type=value_error, input_value={}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/value_error
[2025-02-22 22:19:22] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:19:33] INFO [RAGChat.agent_excute:73] 1,开始调用llms
[2025-02-22 22:19:40] INFO [RAGChat.agent_excute:78] 1,结束调用llms，共耗时7.012697219848633
[2025-02-22 22:19:40] ERROR [RAGChat.agent_excute:122] agent action call error: 1 validation error for TavilySearchAPIWrapper
  Value error, Did not find tavily_api_key, please add an environment variable `TAVILY_API_KEY` which contains it, or pass `tavily_api_key` as a named parameter. [type=value_error, input_value={}, input_type=dict]
    For further information visit https://errors.pydantic.dev/2.10/v/value_error
[2025-02-22 22:23:20] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:23:27] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 22:23:33] INFO [RAGChat.agent_excute:79] 1,结束调用llms，共耗时5.2254180908203125
[2025-02-22 22:23:35] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 22:23:43] INFO [RAGChat.agent_excute:79] 2,结束调用llms，共耗时8.164397716522217
[2025-02-22 22:26:30] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:26:37] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 22:26:44] INFO [RAGChat.agent_excute:79] 1,结束调用llms，结果为:{'action': {'name': 'online_search', 'args': {'query': 'DeepSeek 有多少个版本'}}, 'thoughts': {'plan': '首先，我需要在网络上搜索有关DeepSeek版本的信息。根据搜索结果，我可以确定DeepSeek有多少个版本。', 'criticism': '在这个阶段，我没有其他更好的方法来获取关于DeepSeek版本的信息，因此这是一个合适的行动。', 'speak': '我将在网络上搜索有关DeepSeek版本的信息。', 'reasoning': '由于我目前没有关于DeepSeek版本的具体信息，因此我需要进行在线搜索以获取相关信息。'}, 'observation': '任务刚开始，需要先收集有关DeepSeek版本的信息。'},共耗时6.298835515975952
[2025-02-22 22:26:46] INFO [RAGChat.online_search:59] online_search result:['DeepSeek开源之路全景回顾：从V1到R1，解读每个模型的技术突破与参数演进 - 知乎 切换模式 写文章 登录/注册 DeepSeek开源之路全景回顾：从V1到R1，解读每个模型的技术突破与参数演进 王成义\u200b 信息技术行业 高级总监 DeepSeek 重新点燃了人们对 AI 的热情，让更多的人接触到了生成式人工智能。 文本介绍一下 DeepSeek 系列主要模型的发布历史及每一代模型的技术突破和参数演进。 DeepSeek-V1 2023年12月发布了 DeepSeek 系列模型的的首个版本 DeepSeek-V1。 DeepSeek-V1 有 7B 和 67B 两个版本，并且分别有基础和聊天的模型。 7B的模型文件约 14G 大小，67B 模型文件约 140G 大小。 • 代码仓库：https://github.com/deepseek-ai/deepseek-LLM 为了训练 DeepSeek-V1 团队，DeepSeek 团队开发了一个数据集， 该数据集目前包含 2 万亿个 token，训练出了 DeepSeek LLM Base 模型。 并且进一步对 DeepSeek LLM Base 模型进行监督微调 (SFT) 和直接偏好优化 (DPO)， 从而创建了 DeepSeek Chat 模型。 DeepSeek LLM 67B 在各种基准测试中都超越了 LLaMA-2 70B。 特别是在代码、数学和推理领域。此外，开 展开阅读全文\u200b 发布于 2025-02-09 01:11・IP 属地北京 开源 \u200b赞同 2\u200b\u200b添加评论 \u200b分享 \u200b喜欢\u200b收藏\u200b申请转载', 'IT之家 2 月5 日消息，中国移动“移动云”今日宣布全面上线DeepSeek，实现全版本覆盖、全尺寸适配、全功能畅用。 全版本：支持DeepSeek V1、V2、V3、R1 等', '一篇搞懂DeepSeek：三种部署方案+版本对比，普通用户这样选！_学习_IT猫仔-DeepSeek技术社区 DeepSeek技术社区 DeepSeek技术社区 DeepSeek技术社区 DeepSeek技术社区 一篇搞懂DeepSeek：三种部署方案+版本对比，普通用户这样选！ 一篇搞懂DeepSeek：三种部署方案+版本对比，普通用户这样选！ IT猫仔 948人浏览 · 2025-02-14 11:22:11 IT猫仔 \u2002·\u2002 2025-02-14 11:22:11 发布 访问DeepSeek官网（https://chat.deepseek.com/），直接输入问题即可对话。 1、 选择模型版本： 蒸馏版（7B/14B参数）：RTX 4060显卡即可运行，但效果缩水。 2、 通过Ollama或vLLM框架部署，支持终端或可视化界面交互。 注册硅基流动账号：官网（https://www.siliconflow.com/zh/home）用手机号登录 1、 V1/V2系列： 2、 V2.5/V3系列： 优势：数学推理和联网搜索提升，性能对标GPT-4。 3、 R1系列： 蒸馏版（7B/14B）：本地可跑，但效果仅为满血版的30%。 | 本地部署 | 数据绝对私有安全 ，支持高阶功能定制(本地数据库搭建 | 硬件成本高达百万级 ， 技术门槛极高 | | 硅基流动+华为云 | 低成本用满血版模型 ， 5分钟一键部署 | 依赖网络环境 ， 部分高级功能未开放 | • 基于大模型全栈工程实现（前端、后端、产品经理、设计、数据分析等），通过这门课可获得不同能力； • 能够利用大模型解决相关实际项目需求： 大数据时代，越来越多的企业和机构需要处理海量数据，利用大模型技术可以更好地处理这些数据，提高数据分析和决策的准确性。因此，掌握大模型应用开发技能，可以让程序员更好地应对实际项目需求； • 基于大模型和企业数据AI应用开发，实现大模型理论、掌握GPU算力、硬件、LangChain开发框架和项目实战技能， 学会Fine-tuning垂直训练大模型（数据准备、数据蒸馏、大模型部署）一站式掌握； • 能够完成时下热门大模型垂直领域模型训练能力，提高程序员的编码能力： 大模型应用开发需要掌握机器学习算法、深度学习框架等技术，这些技术的掌握可以提高程序员的编码能力和分析能力，让程序员更加熟练地编写高质量的代码。 DeepSeek技术社区 · DeepSeek-R1 论文解读 —— 强化学习大语言模型新时代来临？ · DeepSeek 使用教程 · 效率飙升 10 倍！目前最流行的国产DeepSeek 如何 “一键” 全自动写代码 DeepSeek-R1 论文解读 —— 强化学习大语言模型新时代来临？ DeepSeek技术社区 DeepSeek 使用教程 DeepSeek 是一款功能强大的机器学习和数据分析工具，适用于各类用户。通过本教程，您可以快速掌握 DeepSeek 的核心功能，并将其应用于实际项目中。在使用过程中遇到问题，请随时联系 DeepSeek 支持团队。 DeepSeek技术社区 效率飙升 10 倍！目前最流行的国产DeepSeek 如何 “一键” 全自动写代码 更让人眼前一亮的是，其API的使用成本极为亲民，每 500 万 tokens 仅仅只需 10 元，而且为助力新用户轻松迈出探索的第一步，还大方地赠送 10 元初始余额，这无疑极大地消除了新手入门的顾虑，降低了尝试的门槛。1、新建 Python 文件夹：在 VScode 中，点击 “文件” 菜单，选择 “新建文件”，将文件命名为 “test202501.py”（当然，你也可以根据实际需求命名），此时 DeepSeek技术社区 IT猫仔', '3. DeepSeek-V2.5系列：数学与网络搜索突破 DeepSeek - V2.5 vs ChatGPT4o - latest：DeepSeek - V2.5的胜率为43%，平局率为8%，败率为49% 。 DeepSeek - V2 vs ChatGPT4o - latest：DeepSeek - V2的胜率为31%，平局率为8%，败率为61% 。 DeepSeek - V2.5 vs ChatGPT4o mini：DeepSeek - V2.5的胜率为66%，平局率为9%，败率为25% 。 DeepSeek - V2 vs ChatGPT4o mini：DeepSeek - V2的胜率为53%，平局率为9%，败率为38% 。 DeepSeek-V2.5在前一个版本的基础上进行了一些关键性改进，尤其是在数学推理和写作领域，表现得更加优异。同时，该版本加入了联网搜索功能，能够实时分析海量网页信息，增强了模型的实时性和数据丰富度。 DeepSeek - R1 - Lite - Preview 在数学竞赛（AIME、MATH - 500）和世界级编程竞赛（Codeforces）的测试任务中表现突出，在理工科博士生测试、另一世界级编程竞赛和自然语言解谜任务中也有不错表现，但在理工科博士生测试、自然语言解谜等任务中，OpenAI o1 - preview 得分更优，这也是DeepSeek - R1 - Lite没有得到太多关注的原因 。 DeepSeek-V3 多项评测成绩超越了 Qwen2.5-72B 和 Llama-3.1-405B 等其他开源模型，并在性能上和世界顶尖的闭源模型 GPT-4o 以及 Claude-3.5-Sonnet 不分伯仲。 DeepSeek - V3 在 MMLU - Pro、MATH 500、Codeforces 任务测试中表现突出，准确率领先；在 GPQA Diamond、SWE - bench Verified 任务中也有不错表现，但在 AIME 2024 任务中，GPT - 4o - 0513 准确率更优。 DeepSeek - R1 - Distill - Llama系列：在多项测试表现不错，DeepSeek - R1 - Distill - Llama - 70B在MATH - 500 pass@1得94.5 。 3. DeepSeek-V2.5系列：数学与网络搜索突破', '最全的DeepSeek访问以及使用方法|电脑|密钥|命令提示符|deepseek_网易订阅 网易首页 应用 网易新闻 房产 / 家居 网易首页 > 网易号 > 正文 申请入驻 最全的DeepSeek访问以及使用方法 2025-02-02 09:16:16\u3000来源: 平凡AI 海外 \xa0举报 1 【最推荐】官方使用方法：满血版的DeepSeek V3和R1 2 【最保险】本地部署：非满血版的DeepSeek V3和R1 3 【最极客】 API+客户端：次满血版的DeepSeek V3和R1 访问链接：https://chat.deepseek.com/，可以在任何设备和浏览器打开，手机和电脑等都没有问题。 Ollama是一个集成主流AI大模型的网站，使用是免费的，地址为：https://ollama.com/ 这是DeepSeek R1的链接：https://ollama.com/library/deepseek-r1:1.5b API+客户端 通过这个链接进行注册：https://siliconflow.cn/，然后根据下图进行密钥创建。 https://xcn2d971vuw4.feishu.cn/wiki/RaC2w1iiFijAa1kVJUjcp3agn8e#share-TpaYdvpxcoLiS6x3PSfcqb4InOg Notice: The content above (including the pictures and videos if any) is uploaded and posted by a user of NetEase Hao, which is a social media platform and only provides information storage services. 亿咖通科技：ECARX AutoGPT 完成 DeepSeek - R1 模型深度适配 长城汽车 Coffee Agent 与 DeepSeek 已深度融合 平凡AI 6.99万元起 捷途X70/X90 PLUS/大圣超越版限时一口价 限时以旧换新 捷途山海T1最低12.98万元起 公开课 | 史上最完美的【八段锦】教学 家居 公开课 公开课 © 1997-2025 网易公司版权所有 About NetEase | 公司简介 | 联系方法 | 招聘信息 | 客户服务 | 隐私政策 | 不良信息举报 Complaint Center | 廉正举报 | 侵权投诉 Reporting Infringements']
[2025-02-22 22:26:46] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 22:26:53] INFO [RAGChat.agent_excute:79] 2,结束调用llms，结果为:{},共耗时7.052930116653442
[2025-02-22 22:34:21] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:34:33] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 22:34:41] INFO [RAGChat.agent_excute:79] 1,结束调用llms，结果为:{'action': {'name': 'online_search', 'args': {'query': 'deepseek-r1 版本数量'}}, 'thoughts': {'plan': '首先，我需要搜索互联网以确定deepseek-r1有多少个版本。一旦找到了这个信息，我将直接返回结果给用户。', 'criticism': '在搜索之前，我没有足够的信息来回答这个问题，所以这是必要的一步。', 'speak': '正在查找deepseek-r1的版本信息。', 'reasoning': '由于我对deepseek-r1的具体版本数量没有预先训练的知识，因此需要在线搜索以获取最准确的信息。'}, 'observation': '任务刚开始，正在收集必要的信息以完成任务。'},共耗时7.603015184402466
[2025-02-22 22:34:44] INFO [RAGChat.online_search:59] online_search result:['DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法）-腾讯云开发者社区-腾讯云 AntDream DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） 关注作者 前往小程序，Get_更优_阅读体验！ 立即前往 腾讯云 开发者社区 文档建议反馈控制台 登录/注册 首页 学习 文章/答案/技术大牛搜索 AntDream 社区首页 >专栏 >DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） AntDream DeepSeek-R1系列模型是基于Transformer架构的大型语言模型，支持中英文双语处理。该系列模型通过不断优化算法和增加训练数据，逐步提升了模型的性能和适用性。 R1-35B R1-671B R1-13B R1-7B R1-7B 是最轻量化的版本，适合移动设备或边缘计算场景。 R1-13B 在性能和资源消耗之间找到了平衡，适合大多数企业级应用。 R1-35B 和 R1-671B 则分别针对高复杂度和超大规模任务设计，适合云计算和高性能计算环境。 R1-7B 的训练数据经过精简，专注于核心任务，适合对计算资源敏感的场景。 R1-35B 和 R1-671B 则引入了更多样化的数据集，尤其是多模态数据（如图像、音频等），使其能够处理更复杂的任务。 R1-7B 和 R1-13B 更适合对实时性要求较高的场景。 R1-35B 和 R1-671B 则更适合需要高精度和复杂推理的任务。 R1-7B 对硬件要求最低，适合个人开发者或小企业。 R1-671B 则需要高性能计算集群支持，适合大型企业或科研机构。 如果你的任务是简单的文本生成或对话交互，可以选择 R1-7B 或 R1-13B。 如果需要处理复杂推理或多模态任务，则建议选择 R1-35B 或 R1-671B。 如果你的设备配置较低（如消费级GPU），请选择 R1-7B。 如果你拥有高性能计算集群，则可以考虑 R1-671B。 R1-7B 和 R1-13B 的使用成本较低，适合预算有限的用户。 R1-35B 和 R1-671B 的成本较高，适合大型企业和科研机构。 DeepSeek-R1系列模型通过不同的参数量和优化方向，为各种场景提供了灵活的选择。以下是各版本的核心特点总结： 本文参与\xa0腾讯云自媒体同步曝光计划，分享自微信公众号。 原始发表：2025-02-07，如有侵权请联系\xa0cloudcommunity@tencent.com 删除 DeepSeek 本文分享自 AntDream 微信公众号，前往查看 如有侵权，请联系 cloudcommunity@tencent.com 删除。 本文参与\xa0腾讯云自媒体同步曝光计划\xa0 ，欢迎热爱写作的你一起参与！ DeepSeek 登录 后参与评论 文章 0获赞 0 高性能应用服务 高性能应用服务(Hyper Application Inventor，HAI)是一款面向AI、科学计算的GPU算力服务产品，提供即插即用的澎湃算力与常见环境。助力中小企业及开发者快速部署LLM、AI作画、数据科学等高性能应用，原生集成配套的开发工具与组件，大幅提高应用层的开发生产效率。 Copyright © 2013 - 2025 Tencent Cloud. 腾讯云 版权所有 Copyright © 2013 - 2025 Tencent Cloud. 腾讯云 版权所有 登录 后参与评论', 'DeepSeek-R1本地部署如何选择适合你的版本?看这里 - kaizi1992 - 博客园 会员 周边 众包 新闻 博问 闪存 赞助商 Chat2DB 所有博客 当前博客 博客园 DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署：选择最适合你的版本，轻松搞定！ DeepSeek-R1的不同类型及含义 DeepSeek-R1有多个不同的类型，每个类型的名称后面跟着一个数字（比如1.5B、7B、14B等），这些数字代表模型的参数量。参数量直接决定了模型的计算能力和存储需求，数字越大，模型越强，但也需要更多的硬件资源。 DeepSeek-R1类型信息表格 显卡：中等性能显卡，如NVIDIA GTX 1650或RTX 2060。 内存：16GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 CPU：8核以上处理器，如Intel i9或AMD Ryzen 9。 显卡：NVIDIA RTX 3080或更强。 内存：64GB RAM。 显卡：NVIDIA RTX 3090、A100或V100显卡。 内存：128GB RAM。 显卡：NVIDIA A100、V100显卡，甚至需要多个显卡配置。 内存：128GB RAM。 显卡：NVIDIA A100或多个V100显卡，甚至需要集群支持。 内存：至少512GB RAM。 1.5B (15亿参数) 7B (70亿参数) 8B (80亿参数) 与上一个版本的计算能力比较：相比7B，计算能力提升 14%，推理能力有所增强，但增幅较小。 与上一个版本的生成质量比较：相比7B，生成质量提升 20%，生成的文本更加自然、准确，适应更复杂的语境。 14B (140亿参数) 与上一个版本的计算能力比较：相比8B，计算能力提升 75%，能够处理更复杂的语境和任务。 与上一个版本的生成质量比较：相比8B，生成质量提升 30%，长篇生成更连贯、自然，文本质量大幅提升。 32B (320亿参数) 与上一个版本的计算能力比较：相比14B，计算能力提升 129%，可以处理更多复杂任务。 与上一个版本的生成质量比较：相比14B，生成质量提升 40%，文本质量接近人工水平，适合高级写作和深度理解。 70B (700亿参数) 与上一个版本的计算能力比较：相比32B，计算能力提升 119%，能够处理更加复杂的推理和生成任务。 与上一个版本的生成质量比较：相比32B，生成质量提升 50%，文本质量更加精细，几乎无明显错误，适用于创意和高精度任务。 671B (6710亿参数) 与上一个版本的计算能力比较：相比70B，计算能力提升 860%，能够处理极为复杂的推理任务和大规模内容生成。 与上一个版本的生成质量比较：相比70B，生成质量提升 100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂的任务。 计算能力：从1.5B到671B，每个版本相对于前一个版本的计算能力都有显著提升，尤其是从 70B 到 671B，计算能力的大幅度提升说明了超大模型在推理复杂性上的巨大优势。 生成质量：生成质量从 1.5B 到 671B 逐步提升，每个新版本生成的文本更加自然、流畅，能够处理更复杂的上下文和细节。尤其是 70B 和 671B 版本的文本生成已经达到了极高水平，几乎可以媲美人工写作。 posted @ 2025-02-11 13:03\xa0 kaizi1992\xa0 阅读(3155)\xa0 评论(6)\xa0 编辑\xa0 收藏\xa0 举报 Copyright © 2025 kaizi1992', 'DeepSeek R1 入门指南：架构、训练、本地部署和硬件要求 DeepSeek-R1 不是一个单一的模型，而是一系列模型，包括：DeepSeek-R1-Zero 和 DeepSeek-R1。主要区别DeepSeek-R1-Zero 代表团队使用纯强化学习而不进行任何监督微调的初步实验。他们从基础模型开始，直接应用强化学习，让模型通过试错过程发展推理能力。虽然这种方法取得了令人印象深刻的结果（在 AIME 2024 上达到 71% 的准确率），但在可读性和语言 DeepSeek-R1 的技术概述 DeepSeek-R1 不是一个单一的模型，而是一系列模型，包括：DeepSeek-R1-Zero 和 DeepSeek-R1。 让我说明一下 DeepSeek-R1 和 DeepSeek-R1-Zero 之间的关键区别： DeepSeek-R1-Zero 代表团队使用纯强化学习而不进行任何监督微调的初步实验。他们从基础模型开始，直接应用强化学习，让模型通过试错过程发展推理能力。虽然这种方法取得了令人印象深刻的结果（在 AIME 2024 上达到 71% 的准确率），但在可读性和语言一致性方面存在一些显著的限制。该模型拥有 6710 亿个参数，采用混合专家（MoE）架构，每个标记激活相当于 370 亿个参数。这个模型展现出了新兴的推理行为，如自我验证、反思和长链思维（CoT）推理。 蒸馏技术： 为了普及高性能模型的访问，DeepSeek 还发布了从 15 亿到 700 亿参数的 R1 蒸馏版本。这些模型基于 Qwen 和 Llama 等架构，表明复杂的推理能力可以被封装在更小、更高效的模型中。蒸馏过程包括使用由完整 DeepSeek-R1 生成的合成推理数据对这些较小的模型进行微调，从而在降低计算成本的同时保持高性能。 DeepSeek-R1-Zero 的训练过程非常简单： DeepSeek-R1 的训练过程则包括四个不同阶段： 推理基准测试： DeepSeek-R1 在各种基准测试中表现出色： 成本效益： DeepSeek-R1 的 API 定价为每百万输入标记 0.14 美元，对于缓存命中，显著低于类似模型如 OpenAI 的 o1。 开源与许可： DeepSeek-R1 及其变体在 MIT 许可下发布，促进了开源合作和商业使用，包括模型蒸馏。此举对于促进创新和降低 AI 模型开发的门槛至关重要。 使用 API 发送提示并接收 DeepSeek-R1 的响应 接下来，你需要本地下载并运行 DeepSeek R1 模型。 ollama run deepseek-r1:1.5b ollama run deepseek-r1:8b ollama run deepseek-r1:14b ollama run deepseek-r1:32b ollama run deepseek-r1:70b 通过 Ollama 向本地下载的 DeepSeek-R1 发送请求： Ollama 提供了一个 API ，可以以编程方式与 DeepSeek-R1 互动。确保 Ollama 服务器在本地运行后再进行 API 请求。你可以通过运行以下命令启动服务器： 将“你的问题或提示内容”替换为你希望提供给模型的实际输入。该命令向本地 Ollama 服务器发送一个 POST 请求，服务器使用指定的 DeepSeek-R1 模型处理提示并返回生成的响应。', 'GreenForestQuan 模型版本    模型大小    CPU 显卡  内存  磁盘空间 1.5B    1.1GB   普通四核或六核处理器就行    NVIDIA GTX 1650或RTX 2060这种中等性能显卡    16GB RAM    至少50GB空闲空间 7B  4.7GB   6核或8核处理器    NVIDIA RTX 3060或更强的显卡   32GB RAM    至少100GB空闲空间 8B  4.9GB   6核或8核处理器    NVIDIA RTX 3060或更强的显卡   32GB RAM    至少100GB空闲空间 14B 9GB 8核以上处理器，像Intel i9或AMD Ryzen 9   NVIDIA RTX 3080或更强的显卡   64GB RAM    至少200GB空闲空间 32B 20GB    8核以上处理器 NVIDIA RTX 3090、A100或V100显卡 128GB RAM   至少500GB空闲空间 70B 43GB    12核以上处理器，推荐用高端Intel或AMD处理器  NVIDIA A100、V100显卡，可能还得多个显卡一起用  128GB RAM   至少1TB空闲空间 671B    404GB   高性能、多核CPU，建议多台服务器配置 NVIDIA A100或多个V100显卡，甚至需要集群支持   至少512GB RAM 至少2TB空闲空间 模型版本    主要功能    与上一版本计算能力比较 与上一版本生成质量比较 8B（80亿参数）   适用于高质量对话生成、短文本总结、复杂问题解答等    比7B计算能力提升14%，推理能力有增强，但增幅较小  比7B生成质量提升20%，生成文本更自然、准确，适应更复杂语境 14B（140亿参数） 用于高级语言理解、长篇文本生成、高级推理等任务 比8B计算能力提升75%，能处理更复杂语境和任务    比8B生成质量提升30%，长篇生成更连贯、自然，文本质量大幅提升 32B（320亿参数） 适合复杂推理任务、高级写作、长篇对话生成等   比14B计算能力提升129%，能处理更多复杂任务    比14B生成质量提升40%，文本质量接近人工水平，适合高级写作和深度理解 70B（700亿参数） 用于深度语义理解、创意写作、多模态推理等高端应用    比32B计算能力提升119%，能处理更复杂推理和生成任务    比32B生成质量提升50%，文本质量更精细，几乎无明显错误，适用于创意和高精度任务 671B（6710亿参数）   用于超高精度推理、大规模内容生成、跨领域深度理解等任务 比70B计算能力提升860%，能处理极为复杂推理任务和大规模内容生成  比70B生成质量提升100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂任务 GreenForestQuan posted @ 2025-02-12 11:54\xa0 GreenForestQuan\xa0 阅读(1010)\xa0 评论(2)\xa0 编辑\xa0 收藏\xa0 举报 DeepSeek-R1本地部署如何选择适合你的版本?看这里 · DeepSeek-R1本地部署如何选择适合你的版本?看这里 昵称： GreenForestQuan 2.技术的八荣八耻 linux(6) @fyjsnow 一般来说，模型的大小主要是指模型所包含的参数数量以及这些参数所占用的内存空间等，而占用磁盘空间则涉及到更多因素，以下是对它们关系的理解以及对所举例子中差异情况的分析： 模型大小与占用... --GreenForestQuan --fyjsnow --GreenForestQuan', 'DeepSeek-R1本地部署如何选择适合你的版本?看这里-腾讯云开发者社区-腾讯云 DeepSeek-R1本地部署如何选择适合你的版本?看这里 登录/注册 文章/答案/技术大牛搜索 社区首页 >专栏 >DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署：选择最适合你的版本，轻松搞定！ DeepSeek-R1的不同类型及含义 DeepSeek-R1类型信息表格 显卡：中等性能显卡，如NVIDIA GTX 1650或RTX 2060。 内存：16GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 CPU：8核以上处理器，如Intel i9或AMD Ryzen 9。 显卡：NVIDIA RTX 3080或更强。 内存：64GB RAM。 显卡：NVIDIA RTX 3090、A100或V100显卡。 内存：128GB RAM。 内存：128GB RAM。 内存：至少512GB RAM。 1.5B (15亿参数) 7B (70亿参数) 8B (80亿参数) 与上一个版本的计算能力比较：相比7B，计算能力提升 14%，推理能力有所增强，但增幅较小。 与上一个版本的生成质量比较：相比7B，生成质量提升 20%，生成的文本更加自然、准确，适应更复杂的语境。 14B (140亿参数) 与上一个版本的计算能力比较：相比8B，计算能力提升 75%，能够处理更复杂的语境和任务。 与上一个版本的生成质量比较：相比8B，生成质量提升 30%，长篇生成更连贯、自然，文本质量大幅提升。 与上一个版本的计算能力比较：相比14B，计算能力提升 129%，可以处理更多复杂任务。 与上一个版本的生成质量比较：相比14B，生成质量提升 40%，文本质量接近人工水平，适合高级写作和深度理解。 与上一个版本的计算能力比较：相比32B，计算能力提升 119%，能够处理更加复杂的推理和生成任务。 与上一个版本的生成质量比较：相比32B，生成质量提升 50%，文本质量更加精细，几乎无明显错误，适用于创意和高精度任务。 与上一个版本的计算能力比较：相比70B，计算能力提升 860%，能够处理极为复杂的推理任务和大规模内容生成。 与上一个版本的生成质量比较：相比70B，生成质量提升 100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂的任务。 计算能力：从1.5B到671B，每个版本相对于前一个版本的计算能力都有显著提升，尤其是从 70B 到 671B，计算能力的大幅度提升说明了超大模型在推理复杂性上的巨大优势。 生成质量：生成质量从 1.5B 到 671B 逐步提升，每个新版本生成的文本更加自然、流畅，能够处理更复杂的上下文和细节。尤其是 70B 和 671B 版本的文本生成已经达到了极高水平，几乎可以媲美人工写作。 如有侵权，请联系 cloudcommunity@tencent.com 删除。 DeepSeek 如有侵权，请联系 cloudcommunity@tencent.com 删除。 DeepSeek #deepSeek 登录 后参与评论 文章 0获赞 0 高性能应用服务 高性能应用服务(Hyper Application Inventor，HAI)是一款面向AI、科学计算的GPU算力服务产品，提供即插即用的澎湃算力与常见环境。助力中小企业及开发者快速部署LLM、AI作画、数据科学等高性能应用，原生集成配套的开发工具与组件，大幅提高应用层的开发生产效率。 Copyright © 2013 - 2025 Tencent Cloud. Copyright © 2013 - 2025 Tencent Cloud. 登录 后参与评论']
[2025-02-22 22:34:44] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 22:34:51] INFO [RAGChat.agent_excute:79] 2,结束调用llms，结果为:{},共耗时7.8130316734313965
[2025-02-22 22:36:48] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:36:57] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 22:37:04] INFO [RAGChat.agent_excute:79] 1,结束调用llms，结果为:{'action': {'name': 'online_search', 'args': {'query': 'response什么意思'}}, 'thoughts': {'plan': "通过在线搜索查询来获取'response'的含义，以便准确地回答用户的问题。", 'criticism': '在这个情况下，直接使用我的训练知识来回答可能是更高效的。但是，根据指示我需要展示如何选择并执行一个动作。', 'speak': "正在查找'response'的意思。", 'reasoning': '用户询问了一个术语的定义，最直接的方法是进行在线搜索以确保提供最新和最准确的信息。'}, 'observation': "任务开始：用户询问了'response'的意思。"},共耗时6.271291255950928
[2025-02-22 22:37:06] INFO [RAGChat.online_search:59] online_search result:['response意思是n.反应;回答，答复;[宗]回应经文，应唱圣歌. 英[rɪˈspɒns] 美[rɪˈspɑ:ns]. 1、His response is one of anger and frustration.', 'RESPONSE翻译：回答;回应，反应, （宗教礼拜仪式中会众对牧师的）唱和，应答。了解更多。', 'response. 英. [rɪˈspɒns]. 美. [rɪˈspɑːns]. n. （口头的或书面的）回答，答复;反应;响应;（礼拜仪式中的）答唱咏，启应经.', 'This means quick response without lengthy travel time. 这意味着快速响应并免除了漫长的差旅时间。 Increased fluorescence quantification and supreme mass', 'respond回 ; reaction反 ，感 ; reply回 ; rebuttal反驳; responsiveness 性; prompt敏捷的，迅速的; answer符合; request请求; feedback反馈; elicit引出, 探出;']
[2025-02-22 22:37:06] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 22:37:14] INFO [RAGChat.agent_excute:79] 2,结束调用llms，结果为:{},共耗时8.401529550552368
[2025-02-22 22:38:17] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:38:27] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 22:38:36] INFO [RAGChat.agent_excute:79] 1,结束调用llms，结果为:{'action': {'name': 'write_to_file', 'args': {'file_name': 'response_meaning.txt', 'content': "response在英语中的意思是'回应'或'回答'。在网络和编程的上下文中，它通常指服务器、程序或系统对请求的回复。"}}, 'thoughts': {'plan': "将'response'的意思写入文件，然后读取文件内容以确认写入成功。", 'criticism': "无需进行在线搜索，因为我已经知道'response'的意思。", 'speak': "已将'response'的意思写入文件。", 'reasoning': '直接提供信息比通过网络搜索更高效，因为作为语言模型，我已经有足够的知识来回答这个问题。'}, 'observation': '任务正在按计划进行，接下来需要确认信息是否正确写入文件。'},共耗时8.829688549041748
[2025-02-22 22:38:36] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 22:38:44] INFO [RAGChat.agent_excute:79] 2,结束调用llms，结果为:{},共耗时7.9482715129852295
[2025-02-22 22:44:26] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:44:33] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 22:44:42] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:44:51] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 22:44:58] INFO [RAGChat.agent_excute:79] 1,结束调用llms，结果为:{'action': {'name': 'write_to_file', 'args': {'file_name': 'response_meaning.txt', 'content': 'response的意思是回应或回复。在不同的场景中，它可以指代对问题的答案、对事件的反应或是系统对用户输入的反馈。'}}, 'thoughts': {'plan': '将response的解释写入文件，然后读取文件内容以确认写入成功。', 'criticism': '无需改进，直接给出response的定义即可满足用户需求。', 'speak': '已将response的含义写入文件。', 'reasoning': '用户询问了response的含义，根据我的知识库，我直接给出了定义并将其写入文件。'}, 'observation': '任务进展顺利，已经为用户提供了一个关于response含义的简明解释。'},共耗时7.040834665298462
[2025-02-22 22:44:58] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 22:45:07] INFO [RAGChat.agent_excute:79] 2,结束调用llms，结果为:{},共耗时9.129311561584473
[2025-02-22 22:45:07] ERROR [RAGChat.agent_excute:84] 调用结果出错，结果如：{},即将重试
[2025-02-22 22:45:07] INFO [RAGChat.agent_excute:74] 3,开始调用llms
[2025-02-22 22:45:16] INFO [RAGChat.agent_excute:79] 3,结束调用llms，结果为:{},共耗时8.979176759719849
[2025-02-22 22:45:16] ERROR [RAGChat.agent_excute:84] 调用结果出错，结果如：{},即将重试
[2025-02-22 22:45:16] INFO [RAGChat.agent_excute:74] 4,开始调用llms
[2025-02-22 22:45:25] INFO [RAGChat.agent_excute:79] 4,结束调用llms，结果为:{'action': {'name': 'write_to_file', 'args': {'file_name': 'response_meaning.txt', 'content': 'Response refers to an answer or reply given to a question or request. In programming or web development, it often means the data sent back by a server to a client after a request.'}}, 'thoughts': {'plan': '定义response的含义并将其写入文件，然后确认写入是否成功。', 'criticism': '直接给出response的定义可以满足用户需求，但通过写入和读取文件来确认操作成功也是一个合理的步骤。', 'speak': '正在将response的定义写入文件中。', 'reasoning': '用户询问了response的含义，根据我的知识库，我直接给出了定义并将其写入文件。'}, 'observation': '已经执行了将response定义写入文件的操作。'},共耗时8.443218469619751
[2025-02-22 22:45:25] INFO [RAGChat.agent_excute:74] 5,开始调用llms
[2025-02-22 22:45:35] INFO [RAGChat.agent_excute:79] 5,结束调用llms，结果为:{},共耗时10.364320039749146
[2025-02-22 22:45:35] ERROR [RAGChat.agent_excute:84] 调用结果出错，结果如：{},即将重试
[2025-02-22 22:45:35] INFO [RAGChat.agent_excute:74] 6,开始调用llms
[2025-02-22 22:45:47] INFO [RAGChat.agent_excute:79] 6,结束调用llms，结果为:{},共耗时12.232339143753052
[2025-02-22 22:45:47] ERROR [RAGChat.agent_excute:84] 调用结果出错，结果如：{},即将重试
[2025-02-22 22:45:47] INFO [RAGChat.agent_excute:74] 7,开始调用llms
[2025-02-22 22:45:56] INFO [RAGChat.agent_excute:79] 7,结束调用llms，结果为:{},共耗时8.636447668075562
[2025-02-22 22:45:56] ERROR [RAGChat.agent_excute:84] 调用结果出错，结果如：{},即将重试
[2025-02-22 22:45:56] INFO [RAGChat.agent_excute:74] 8,开始调用llms
[2025-02-22 22:46:05] INFO [RAGChat.agent_excute:79] 8,结束调用llms，结果为:{},共耗时8.9492666721344
[2025-02-22 22:46:05] ERROR [RAGChat.agent_excute:84] 调用结果出错，结果如：{},即将重试
[2025-02-22 22:46:05] INFO [RAGChat.agent_excute:74] 9,开始调用llms
[2025-02-22 22:46:16] INFO [RAGChat.agent_excute:79] 9,结束调用llms，结果为:{},共耗时10.934362888336182
[2025-02-22 22:46:16] ERROR [RAGChat.agent_excute:84] 调用结果出错，结果如：{},即将重试
[2025-02-22 22:46:16] INFO [RAGChat.agent_excute:74] 10,开始调用llms
[2025-02-22 22:51:02] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:51:11] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 22:51:20] INFO [RAGChat.agent_excute:79] 1,结束调用llms,共耗时8.43192195892334
[2025-02-22 22:51:20] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{
    "action": {
        "name": "finish",
        "args": {
            "answer": "response一词的意思取决于它所处的上下文，但通常它指的是对一个问题、请求或刺激的回复或反应。在计算机和互联网术语中，它可以指服务器或系统对请求作出的回应。"
        }
    },
    "thoughts": {
        "plan": "直接完成任务，因为对于'response'这个词的解释不需要额外的信息收集或文件操作。",
        "criticism": "无需改进，因为这个问题可以通过现有的知识库直接回答。",
        "speak": "已提供'response'的定义作为回答。",
        "reasoning": "考虑到问题是关于一个常见英文单词的意思，且没有特定的背景信息提示需要更深入的研究，最有效的方法是立即给出答案并完成任务。"
    },
    "observation": "任务已经完成，提供了'response'的含义作为答案。"
},即将重试
[2025-02-22 22:51:20] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 22:51:27] INFO [RAGChat.agent_excute:79] 2,结束调用llms,共耗时7.947925090789795
[2025-02-22 22:51:27] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{
    "action": {
        "name": "finish",
        "args": {
            "answer": "response在英语中的意思是对某事物的回应或回答。它可以是对于一个问题、请求、攻击、挑战等的反应。在计算机和互联网技术中，response通常指的是服务器对客户端请求的回应。"
        }
    },
    "thoughts": {
        "plan": "直接完成任务，提供response的定义",
        "criticism": "无需改进，因为问题简单明了，不需要额外步骤",
        "speak": "我已经找到了response的意思。",
        "reasoning": "根据我的知识库，我能够直接给出response的含义，所以可以直接完成任务。"
    },
    "observation": "任务已经完成，提供了response的定义。"
},即将重试
[2025-02-22 22:51:27] INFO [RAGChat.agent_excute:74] 3,开始调用llms
[2025-02-22 22:51:35] INFO [RAGChat.agent_excute:79] 3,结束调用llms,共耗时7.8336169719696045
[2025-02-22 22:51:35] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{
    "action": {
        "name": "finish",
        "args": {
            "answer": "response在英语中的意思是对某个问题、请求或刺激做出的回应或回答。它可以是言语上的回答，也可以是非言语的行为反应。"
        }
    },
    "thoughts": {
        "plan": "直接完成用户目标，提供response的定义。",
        "criticism": "无需改进，因为这是一个简单的定义查询，不需要额外的动作。",
        "speak": "已提供response的含义。",
        "reasoning": "用户询问response的意思，作为一个常见的英文单词，可以直接给出其定义，无需进行网络搜索或其他操作。"
    },
    "observation": "任务已经完成，提供了response的定义。"
},即将重试
[2025-02-22 22:51:35] INFO [RAGChat.agent_excute:74] 4,开始调用llms
[2025-02-22 22:54:10] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:54:18] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 22:54:24] INFO [RAGChat.agent_excute:79] 1,结束调用llms,共耗时6.346680402755737
[2025-02-22 22:54:24] INFO [RAGChat.agent_excute:113] 对于问题response什么意思的结果是：response在英语中的意思是'回应'或'回答'，它指的是对一个问题、要求或行动所作出的反应。
[2025-02-22 22:54:46] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 22:54:53] INFO [RAGChat.agent_excute:79] 1,结束调用llms,共耗时7.48777174949646
[2025-02-22 22:54:57] INFO [RAGChat.online_search:59] online_search result:['DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法）-腾讯云开发者社区-腾讯云 AntDream DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） 关注作者 前往小程序，Get_更优_阅读体验！ 立即前往 腾讯云 开发者社区 文档建议反馈控制台 登录/注册 首页 学习 文章/答案/技术大牛搜索 AntDream 社区首页 >专栏 >DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） AntDream DeepSeek-R1系列模型是基于Transformer架构的大型语言模型，支持中英文双语处理。该系列模型通过不断优化算法和增加训练数据，逐步提升了模型的性能和适用性。 R1-35B R1-671B R1-13B R1-7B R1-7B 是最轻量化的版本，适合移动设备或边缘计算场景。 R1-13B 在性能和资源消耗之间找到了平衡，适合大多数企业级应用。 R1-35B 和 R1-671B 则分别针对高复杂度和超大规模任务设计，适合云计算和高性能计算环境。 R1-7B 的训练数据经过精简，专注于核心任务，适合对计算资源敏感的场景。 R1-35B 和 R1-671B 则引入了更多样化的数据集，尤其是多模态数据（如图像、音频等），使其能够处理更复杂的任务。 R1-7B 和 R1-13B 更适合对实时性要求较高的场景。 R1-35B 和 R1-671B 则更适合需要高精度和复杂推理的任务。 R1-7B 对硬件要求最低，适合个人开发者或小企业。 R1-671B 则需要高性能计算集群支持，适合大型企业或科研机构。 如果你的任务是简单的文本生成或对话交互，可以选择 R1-7B 或 R1-13B。 如果需要处理复杂推理或多模态任务，则建议选择 R1-35B 或 R1-671B。 如果你的设备配置较低（如消费级GPU），请选择 R1-7B。 如果你拥有高性能计算集群，则可以考虑 R1-671B。 R1-7B 和 R1-13B 的使用成本较低，适合预算有限的用户。 R1-35B 和 R1-671B 的成本较高，适合大型企业和科研机构。 DeepSeek-R1系列模型通过不同的参数量和优化方向，为各种场景提供了灵活的选择。以下是各版本的核心特点总结： 本文参与\xa0腾讯云自媒体同步曝光计划，分享自微信公众号。 原始发表：2025-02-07，如有侵权请联系\xa0cloudcommunity@tencent.com 删除 DeepSeek 本文分享自 AntDream 微信公众号，前往查看 如有侵权，请联系 cloudcommunity@tencent.com 删除。 本文参与\xa0腾讯云自媒体同步曝光计划\xa0 ，欢迎热爱写作的你一起参与！ DeepSeek 登录 后参与评论 文章 0获赞 0 高性能应用服务 高性能应用服务(Hyper Application Inventor，HAI)是一款面向AI、科学计算的GPU算力服务产品，提供即插即用的澎湃算力与常见环境。助力中小企业及开发者快速部署LLM、AI作画、数据科学等高性能应用，原生集成配套的开发工具与组件，大幅提高应用层的开发生产效率。 Copyright © 2013 - 2025 Tencent Cloud. 腾讯云 版权所有 Copyright © 2013 - 2025 Tencent Cloud. 腾讯云 版权所有 登录 后参与评论', 'DeepSeek-R1本地部署如何选择适合你的版本?看这里 - kaizi1992 - 博客园 会员 周边 众包 新闻 博问 闪存 赞助商 Chat2DB 所有博客 当前博客 博客园 DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署：选择最适合你的版本，轻松搞定！ DeepSeek-R1的不同类型及含义 DeepSeek-R1有多个不同的类型，每个类型的名称后面跟着一个数字（比如1.5B、7B、14B等），这些数字代表模型的参数量。参数量直接决定了模型的计算能力和存储需求，数字越大，模型越强，但也需要更多的硬件资源。 DeepSeek-R1类型信息表格 显卡：中等性能显卡，如NVIDIA GTX 1650或RTX 2060。 内存：16GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 CPU：8核以上处理器，如Intel i9或AMD Ryzen 9。 显卡：NVIDIA RTX 3080或更强。 内存：64GB RAM。 显卡：NVIDIA RTX 3090、A100或V100显卡。 内存：128GB RAM。 显卡：NVIDIA A100、V100显卡，甚至需要多个显卡配置。 内存：128GB RAM。 显卡：NVIDIA A100或多个V100显卡，甚至需要集群支持。 内存：至少512GB RAM。 1.5B (15亿参数) 7B (70亿参数) 8B (80亿参数) 与上一个版本的计算能力比较：相比7B，计算能力提升 14%，推理能力有所增强，但增幅较小。 与上一个版本的生成质量比较：相比7B，生成质量提升 20%，生成的文本更加自然、准确，适应更复杂的语境。 14B (140亿参数) 与上一个版本的计算能力比较：相比8B，计算能力提升 75%，能够处理更复杂的语境和任务。 与上一个版本的生成质量比较：相比8B，生成质量提升 30%，长篇生成更连贯、自然，文本质量大幅提升。 32B (320亿参数) 与上一个版本的计算能力比较：相比14B，计算能力提升 129%，可以处理更多复杂任务。 与上一个版本的生成质量比较：相比14B，生成质量提升 40%，文本质量接近人工水平，适合高级写作和深度理解。 70B (700亿参数) 与上一个版本的计算能力比较：相比32B，计算能力提升 119%，能够处理更加复杂的推理和生成任务。 与上一个版本的生成质量比较：相比32B，生成质量提升 50%，文本质量更加精细，几乎无明显错误，适用于创意和高精度任务。 671B (6710亿参数) 与上一个版本的计算能力比较：相比70B，计算能力提升 860%，能够处理极为复杂的推理任务和大规模内容生成。 与上一个版本的生成质量比较：相比70B，生成质量提升 100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂的任务。 计算能力：从1.5B到671B，每个版本相对于前一个版本的计算能力都有显著提升，尤其是从 70B 到 671B，计算能力的大幅度提升说明了超大模型在推理复杂性上的巨大优势。 生成质量：生成质量从 1.5B 到 671B 逐步提升，每个新版本生成的文本更加自然、流畅，能够处理更复杂的上下文和细节。尤其是 70B 和 671B 版本的文本生成已经达到了极高水平，几乎可以媲美人工写作。 posted @ 2025-02-11 13:03\xa0 kaizi1992\xa0 阅读(3155)\xa0 评论(6)\xa0 编辑\xa0 收藏\xa0 举报 Copyright © 2025 kaizi1992', 'DeepSeek R1 入门指南：架构、训练、本地部署和硬件要求 DeepSeek-R1 不是一个单一的模型，而是一系列模型，包括：DeepSeek-R1-Zero 和 DeepSeek-R1。主要区别DeepSeek-R1-Zero 代表团队使用纯强化学习而不进行任何监督微调的初步实验。他们从基础模型开始，直接应用强化学习，让模型通过试错过程发展推理能力。虽然这种方法取得了令人印象深刻的结果（在 AIME 2024 上达到 71% 的准确率），但在可读性和语言 DeepSeek-R1 的技术概述 DeepSeek-R1 不是一个单一的模型，而是一系列模型，包括：DeepSeek-R1-Zero 和 DeepSeek-R1。 让我说明一下 DeepSeek-R1 和 DeepSeek-R1-Zero 之间的关键区别： DeepSeek-R1-Zero 代表团队使用纯强化学习而不进行任何监督微调的初步实验。他们从基础模型开始，直接应用强化学习，让模型通过试错过程发展推理能力。虽然这种方法取得了令人印象深刻的结果（在 AIME 2024 上达到 71% 的准确率），但在可读性和语言一致性方面存在一些显著的限制。该模型拥有 6710 亿个参数，采用混合专家（MoE）架构，每个标记激活相当于 370 亿个参数。这个模型展现出了新兴的推理行为，如自我验证、反思和长链思维（CoT）推理。 蒸馏技术： 为了普及高性能模型的访问，DeepSeek 还发布了从 15 亿到 700 亿参数的 R1 蒸馏版本。这些模型基于 Qwen 和 Llama 等架构，表明复杂的推理能力可以被封装在更小、更高效的模型中。蒸馏过程包括使用由完整 DeepSeek-R1 生成的合成推理数据对这些较小的模型进行微调，从而在降低计算成本的同时保持高性能。 DeepSeek-R1-Zero 的训练过程非常简单： DeepSeek-R1 的训练过程则包括四个不同阶段： 推理基准测试： DeepSeek-R1 在各种基准测试中表现出色： 成本效益： DeepSeek-R1 的 API 定价为每百万输入标记 0.14 美元，对于缓存命中，显著低于类似模型如 OpenAI 的 o1。 开源与许可： DeepSeek-R1 及其变体在 MIT 许可下发布，促进了开源合作和商业使用，包括模型蒸馏。此举对于促进创新和降低 AI 模型开发的门槛至关重要。 使用 API 发送提示并接收 DeepSeek-R1 的响应 接下来，你需要本地下载并运行 DeepSeek R1 模型。 ollama run deepseek-r1:1.5b ollama run deepseek-r1:8b ollama run deepseek-r1:14b ollama run deepseek-r1:32b ollama run deepseek-r1:70b 通过 Ollama 向本地下载的 DeepSeek-R1 发送请求： Ollama 提供了一个 API ，可以以编程方式与 DeepSeek-R1 互动。确保 Ollama 服务器在本地运行后再进行 API 请求。你可以通过运行以下命令启动服务器： 将“你的问题或提示内容”替换为你希望提供给模型的实际输入。该命令向本地 Ollama 服务器发送一个 POST 请求，服务器使用指定的 DeepSeek-R1 模型处理提示并返回生成的响应。', 'GreenForestQuan 模型版本    模型大小    CPU 显卡  内存  磁盘空间 1.5B    1.1GB   普通四核或六核处理器就行    NVIDIA GTX 1650或RTX 2060这种中等性能显卡    16GB RAM    至少50GB空闲空间 7B  4.7GB   6核或8核处理器    NVIDIA RTX 3060或更强的显卡   32GB RAM    至少100GB空闲空间 8B  4.9GB   6核或8核处理器    NVIDIA RTX 3060或更强的显卡   32GB RAM    至少100GB空闲空间 14B 9GB 8核以上处理器，像Intel i9或AMD Ryzen 9   NVIDIA RTX 3080或更强的显卡   64GB RAM    至少200GB空闲空间 32B 20GB    8核以上处理器 NVIDIA RTX 3090、A100或V100显卡 128GB RAM   至少500GB空闲空间 70B 43GB    12核以上处理器，推荐用高端Intel或AMD处理器  NVIDIA A100、V100显卡，可能还得多个显卡一起用  128GB RAM   至少1TB空闲空间 671B    404GB   高性能、多核CPU，建议多台服务器配置 NVIDIA A100或多个V100显卡，甚至需要集群支持   至少512GB RAM 至少2TB空闲空间 模型版本    主要功能    与上一版本计算能力比较 与上一版本生成质量比较 8B（80亿参数）   适用于高质量对话生成、短文本总结、复杂问题解答等    比7B计算能力提升14%，推理能力有增强，但增幅较小  比7B生成质量提升20%，生成文本更自然、准确，适应更复杂语境 14B（140亿参数） 用于高级语言理解、长篇文本生成、高级推理等任务 比8B计算能力提升75%，能处理更复杂语境和任务    比8B生成质量提升30%，长篇生成更连贯、自然，文本质量大幅提升 32B（320亿参数） 适合复杂推理任务、高级写作、长篇对话生成等   比14B计算能力提升129%，能处理更多复杂任务    比14B生成质量提升40%，文本质量接近人工水平，适合高级写作和深度理解 70B（700亿参数） 用于深度语义理解、创意写作、多模态推理等高端应用    比32B计算能力提升119%，能处理更复杂推理和生成任务    比32B生成质量提升50%，文本质量更精细，几乎无明显错误，适用于创意和高精度任务 671B（6710亿参数）   用于超高精度推理、大规模内容生成、跨领域深度理解等任务 比70B计算能力提升860%，能处理极为复杂推理任务和大规模内容生成  比70B生成质量提升100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂任务 GreenForestQuan posted @ 2025-02-12 11:54\xa0 GreenForestQuan\xa0 阅读(1010)\xa0 评论(2)\xa0 编辑\xa0 收藏\xa0 举报 DeepSeek-R1本地部署如何选择适合你的版本?看这里 · DeepSeek-R1本地部署如何选择适合你的版本?看这里 昵称： GreenForestQuan 2.技术的八荣八耻 linux(6) @fyjsnow 一般来说，模型的大小主要是指模型所包含的参数数量以及这些参数所占用的内存空间等，而占用磁盘空间则涉及到更多因素，以下是对它们关系的理解以及对所举例子中差异情况的分析： 模型大小与占用... --GreenForestQuan --fyjsnow --GreenForestQuan', 'DeepSeek-R1本地部署如何选择适合你的版本?看这里-腾讯云开发者社区-腾讯云 DeepSeek-R1本地部署如何选择适合你的版本?看这里 登录/注册 文章/答案/技术大牛搜索 社区首页 >专栏 >DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署：选择最适合你的版本，轻松搞定！ DeepSeek-R1的不同类型及含义 DeepSeek-R1类型信息表格 显卡：中等性能显卡，如NVIDIA GTX 1650或RTX 2060。 内存：16GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 CPU：8核以上处理器，如Intel i9或AMD Ryzen 9。 显卡：NVIDIA RTX 3080或更强。 内存：64GB RAM。 显卡：NVIDIA RTX 3090、A100或V100显卡。 内存：128GB RAM。 内存：128GB RAM。 内存：至少512GB RAM。 1.5B (15亿参数) 7B (70亿参数) 8B (80亿参数) 与上一个版本的计算能力比较：相比7B，计算能力提升 14%，推理能力有所增强，但增幅较小。 与上一个版本的生成质量比较：相比7B，生成质量提升 20%，生成的文本更加自然、准确，适应更复杂的语境。 14B (140亿参数) 与上一个版本的计算能力比较：相比8B，计算能力提升 75%，能够处理更复杂的语境和任务。 与上一个版本的生成质量比较：相比8B，生成质量提升 30%，长篇生成更连贯、自然，文本质量大幅提升。 与上一个版本的计算能力比较：相比14B，计算能力提升 129%，可以处理更多复杂任务。 与上一个版本的生成质量比较：相比14B，生成质量提升 40%，文本质量接近人工水平，适合高级写作和深度理解。 与上一个版本的计算能力比较：相比32B，计算能力提升 119%，能够处理更加复杂的推理和生成任务。 与上一个版本的生成质量比较：相比32B，生成质量提升 50%，文本质量更加精细，几乎无明显错误，适用于创意和高精度任务。 与上一个版本的计算能力比较：相比70B，计算能力提升 860%，能够处理极为复杂的推理任务和大规模内容生成。 与上一个版本的生成质量比较：相比70B，生成质量提升 100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂的任务。 计算能力：从1.5B到671B，每个版本相对于前一个版本的计算能力都有显著提升，尤其是从 70B 到 671B，计算能力的大幅度提升说明了超大模型在推理复杂性上的巨大优势。 生成质量：生成质量从 1.5B 到 671B 逐步提升，每个新版本生成的文本更加自然、流畅，能够处理更复杂的上下文和细节。尤其是 70B 和 671B 版本的文本生成已经达到了极高水平，几乎可以媲美人工写作。 如有侵权，请联系 cloudcommunity@tencent.com 删除。 DeepSeek 如有侵权，请联系 cloudcommunity@tencent.com 删除。 DeepSeek #deepSeek 登录 后参与评论 文章 0获赞 0 高性能应用服务 高性能应用服务(Hyper Application Inventor，HAI)是一款面向AI、科学计算的GPU算力服务产品，提供即插即用的澎湃算力与常见环境。助力中小企业及开发者快速部署LLM、AI作画、数据科学等高性能应用，原生集成配套的开发工具与组件，大幅提高应用层的开发生产效率。 Copyright © 2013 - 2025 Tencent Cloud. Copyright © 2013 - 2025 Tencent Cloud. 登录 后参与评论']
[2025-02-22 22:54:57] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 22:55:07] INFO [RAGChat.agent_excute:79] 2,结束调用llms,共耗时9.240633726119995
[2025-02-22 22:55:07] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 22:55:07] INFO [RAGChat.agent_excute:74] 3,开始调用llms
[2025-02-22 22:56:59] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 22:57:10] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 22:57:16] INFO [RAGChat.agent_excute:79] 1,结束调用llms,共耗时6.294251203536987
[2025-02-22 22:57:20] INFO [RAGChat.online_search:59] online_search result:['DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法）-腾讯云开发者社区-腾讯云 AntDream DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） 关注作者 前往小程序，Get_更优_阅读体验！ 立即前往 腾讯云 开发者社区 文档建议反馈控制台 登录/注册 首页 学习 文章/答案/技术大牛搜索 AntDream 社区首页 >专栏 >DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） AntDream DeepSeek-R1系列模型是基于Transformer架构的大型语言模型，支持中英文双语处理。该系列模型通过不断优化算法和增加训练数据，逐步提升了模型的性能和适用性。 R1-35B R1-671B R1-13B R1-7B R1-7B 是最轻量化的版本，适合移动设备或边缘计算场景。 R1-13B 在性能和资源消耗之间找到了平衡，适合大多数企业级应用。 R1-35B 和 R1-671B 则分别针对高复杂度和超大规模任务设计，适合云计算和高性能计算环境。 R1-7B 的训练数据经过精简，专注于核心任务，适合对计算资源敏感的场景。 R1-35B 和 R1-671B 则引入了更多样化的数据集，尤其是多模态数据（如图像、音频等），使其能够处理更复杂的任务。 R1-7B 和 R1-13B 更适合对实时性要求较高的场景。 R1-35B 和 R1-671B 则更适合需要高精度和复杂推理的任务。 R1-7B 对硬件要求最低，适合个人开发者或小企业。 R1-671B 则需要高性能计算集群支持，适合大型企业或科研机构。 如果你的任务是简单的文本生成或对话交互，可以选择 R1-7B 或 R1-13B。 如果需要处理复杂推理或多模态任务，则建议选择 R1-35B 或 R1-671B。 如果你的设备配置较低（如消费级GPU），请选择 R1-7B。 如果你拥有高性能计算集群，则可以考虑 R1-671B。 R1-7B 和 R1-13B 的使用成本较低，适合预算有限的用户。 R1-35B 和 R1-671B 的成本较高，适合大型企业和科研机构。 DeepSeek-R1系列模型通过不同的参数量和优化方向，为各种场景提供了灵活的选择。以下是各版本的核心特点总结： 本文参与\xa0腾讯云自媒体同步曝光计划，分享自微信公众号。 原始发表：2025-02-07，如有侵权请联系\xa0cloudcommunity@tencent.com 删除 DeepSeek 本文分享自 AntDream 微信公众号，前往查看 如有侵权，请联系 cloudcommunity@tencent.com 删除。 本文参与\xa0腾讯云自媒体同步曝光计划\xa0 ，欢迎热爱写作的你一起参与！ DeepSeek 登录 后参与评论 文章 0获赞 0 高性能应用服务 高性能应用服务(Hyper Application Inventor，HAI)是一款面向AI、科学计算的GPU算力服务产品，提供即插即用的澎湃算力与常见环境。助力中小企业及开发者快速部署LLM、AI作画、数据科学等高性能应用，原生集成配套的开发工具与组件，大幅提高应用层的开发生产效率。 Copyright © 2013 - 2025 Tencent Cloud. 腾讯云 版权所有 Copyright © 2013 - 2025 Tencent Cloud. 腾讯云 版权所有 登录 后参与评论', 'DeepSeek-R1本地部署如何选择适合你的版本?看这里 - kaizi1992 - 博客园 会员 周边 众包 新闻 博问 闪存 赞助商 Chat2DB 所有博客 当前博客 博客园 DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署：选择最适合你的版本，轻松搞定！ DeepSeek-R1的不同类型及含义 DeepSeek-R1有多个不同的类型，每个类型的名称后面跟着一个数字（比如1.5B、7B、14B等），这些数字代表模型的参数量。参数量直接决定了模型的计算能力和存储需求，数字越大，模型越强，但也需要更多的硬件资源。 DeepSeek-R1类型信息表格 显卡：中等性能显卡，如NVIDIA GTX 1650或RTX 2060。 内存：16GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 CPU：8核以上处理器，如Intel i9或AMD Ryzen 9。 显卡：NVIDIA RTX 3080或更强。 内存：64GB RAM。 显卡：NVIDIA RTX 3090、A100或V100显卡。 内存：128GB RAM。 显卡：NVIDIA A100、V100显卡，甚至需要多个显卡配置。 内存：128GB RAM。 显卡：NVIDIA A100或多个V100显卡，甚至需要集群支持。 内存：至少512GB RAM。 1.5B (15亿参数) 7B (70亿参数) 8B (80亿参数) 与上一个版本的计算能力比较：相比7B，计算能力提升 14%，推理能力有所增强，但增幅较小。 与上一个版本的生成质量比较：相比7B，生成质量提升 20%，生成的文本更加自然、准确，适应更复杂的语境。 14B (140亿参数) 与上一个版本的计算能力比较：相比8B，计算能力提升 75%，能够处理更复杂的语境和任务。 与上一个版本的生成质量比较：相比8B，生成质量提升 30%，长篇生成更连贯、自然，文本质量大幅提升。 32B (320亿参数) 与上一个版本的计算能力比较：相比14B，计算能力提升 129%，可以处理更多复杂任务。 与上一个版本的生成质量比较：相比14B，生成质量提升 40%，文本质量接近人工水平，适合高级写作和深度理解。 70B (700亿参数) 与上一个版本的计算能力比较：相比32B，计算能力提升 119%，能够处理更加复杂的推理和生成任务。 与上一个版本的生成质量比较：相比32B，生成质量提升 50%，文本质量更加精细，几乎无明显错误，适用于创意和高精度任务。 671B (6710亿参数) 与上一个版本的计算能力比较：相比70B，计算能力提升 860%，能够处理极为复杂的推理任务和大规模内容生成。 与上一个版本的生成质量比较：相比70B，生成质量提升 100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂的任务。 计算能力：从1.5B到671B，每个版本相对于前一个版本的计算能力都有显著提升，尤其是从 70B 到 671B，计算能力的大幅度提升说明了超大模型在推理复杂性上的巨大优势。 生成质量：生成质量从 1.5B 到 671B 逐步提升，每个新版本生成的文本更加自然、流畅，能够处理更复杂的上下文和细节。尤其是 70B 和 671B 版本的文本生成已经达到了极高水平，几乎可以媲美人工写作。 posted @ 2025-02-11 13:03\xa0 kaizi1992\xa0 阅读(3155)\xa0 评论(6)\xa0 编辑\xa0 收藏\xa0 举报 Copyright © 2025 kaizi1992', 'DeepSeek R1 入门指南：架构、训练、本地部署和硬件要求 DeepSeek-R1 不是一个单一的模型，而是一系列模型，包括：DeepSeek-R1-Zero 和 DeepSeek-R1。主要区别DeepSeek-R1-Zero 代表团队使用纯强化学习而不进行任何监督微调的初步实验。他们从基础模型开始，直接应用强化学习，让模型通过试错过程发展推理能力。虽然这种方法取得了令人印象深刻的结果（在 AIME 2024 上达到 71% 的准确率），但在可读性和语言 DeepSeek-R1 的技术概述 DeepSeek-R1 不是一个单一的模型，而是一系列模型，包括：DeepSeek-R1-Zero 和 DeepSeek-R1。 让我说明一下 DeepSeek-R1 和 DeepSeek-R1-Zero 之间的关键区别： DeepSeek-R1-Zero 代表团队使用纯强化学习而不进行任何监督微调的初步实验。他们从基础模型开始，直接应用强化学习，让模型通过试错过程发展推理能力。虽然这种方法取得了令人印象深刻的结果（在 AIME 2024 上达到 71% 的准确率），但在可读性和语言一致性方面存在一些显著的限制。该模型拥有 6710 亿个参数，采用混合专家（MoE）架构，每个标记激活相当于 370 亿个参数。这个模型展现出了新兴的推理行为，如自我验证、反思和长链思维（CoT）推理。 蒸馏技术： 为了普及高性能模型的访问，DeepSeek 还发布了从 15 亿到 700 亿参数的 R1 蒸馏版本。这些模型基于 Qwen 和 Llama 等架构，表明复杂的推理能力可以被封装在更小、更高效的模型中。蒸馏过程包括使用由完整 DeepSeek-R1 生成的合成推理数据对这些较小的模型进行微调，从而在降低计算成本的同时保持高性能。 DeepSeek-R1-Zero 的训练过程非常简单： DeepSeek-R1 的训练过程则包括四个不同阶段： 推理基准测试： DeepSeek-R1 在各种基准测试中表现出色： 成本效益： DeepSeek-R1 的 API 定价为每百万输入标记 0.14 美元，对于缓存命中，显著低于类似模型如 OpenAI 的 o1。 开源与许可： DeepSeek-R1 及其变体在 MIT 许可下发布，促进了开源合作和商业使用，包括模型蒸馏。此举对于促进创新和降低 AI 模型开发的门槛至关重要。 使用 API 发送提示并接收 DeepSeek-R1 的响应 接下来，你需要本地下载并运行 DeepSeek R1 模型。 ollama run deepseek-r1:1.5b ollama run deepseek-r1:8b ollama run deepseek-r1:14b ollama run deepseek-r1:32b ollama run deepseek-r1:70b 通过 Ollama 向本地下载的 DeepSeek-R1 发送请求： Ollama 提供了一个 API ，可以以编程方式与 DeepSeek-R1 互动。确保 Ollama 服务器在本地运行后再进行 API 请求。你可以通过运行以下命令启动服务器： 将“你的问题或提示内容”替换为你希望提供给模型的实际输入。该命令向本地 Ollama 服务器发送一个 POST 请求，服务器使用指定的 DeepSeek-R1 模型处理提示并返回生成的响应。', 'GreenForestQuan 模型版本    模型大小    CPU 显卡  内存  磁盘空间 1.5B    1.1GB   普通四核或六核处理器就行    NVIDIA GTX 1650或RTX 2060这种中等性能显卡    16GB RAM    至少50GB空闲空间 7B  4.7GB   6核或8核处理器    NVIDIA RTX 3060或更强的显卡   32GB RAM    至少100GB空闲空间 8B  4.9GB   6核或8核处理器    NVIDIA RTX 3060或更强的显卡   32GB RAM    至少100GB空闲空间 14B 9GB 8核以上处理器，像Intel i9或AMD Ryzen 9   NVIDIA RTX 3080或更强的显卡   64GB RAM    至少200GB空闲空间 32B 20GB    8核以上处理器 NVIDIA RTX 3090、A100或V100显卡 128GB RAM   至少500GB空闲空间 70B 43GB    12核以上处理器，推荐用高端Intel或AMD处理器  NVIDIA A100、V100显卡，可能还得多个显卡一起用  128GB RAM   至少1TB空闲空间 671B    404GB   高性能、多核CPU，建议多台服务器配置 NVIDIA A100或多个V100显卡，甚至需要集群支持   至少512GB RAM 至少2TB空闲空间 模型版本    主要功能    与上一版本计算能力比较 与上一版本生成质量比较 8B（80亿参数）   适用于高质量对话生成、短文本总结、复杂问题解答等    比7B计算能力提升14%，推理能力有增强，但增幅较小  比7B生成质量提升20%，生成文本更自然、准确，适应更复杂语境 14B（140亿参数） 用于高级语言理解、长篇文本生成、高级推理等任务 比8B计算能力提升75%，能处理更复杂语境和任务    比8B生成质量提升30%，长篇生成更连贯、自然，文本质量大幅提升 32B（320亿参数） 适合复杂推理任务、高级写作、长篇对话生成等   比14B计算能力提升129%，能处理更多复杂任务    比14B生成质量提升40%，文本质量接近人工水平，适合高级写作和深度理解 70B（700亿参数） 用于深度语义理解、创意写作、多模态推理等高端应用    比32B计算能力提升119%，能处理更复杂推理和生成任务    比32B生成质量提升50%，文本质量更精细，几乎无明显错误，适用于创意和高精度任务 671B（6710亿参数）   用于超高精度推理、大规模内容生成、跨领域深度理解等任务 比70B计算能力提升860%，能处理极为复杂推理任务和大规模内容生成  比70B生成质量提升100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂任务 GreenForestQuan posted @ 2025-02-12 11:54\xa0 GreenForestQuan\xa0 阅读(1010)\xa0 评论(2)\xa0 编辑\xa0 收藏\xa0 举报 DeepSeek-R1本地部署如何选择适合你的版本?看这里 · DeepSeek-R1本地部署如何选择适合你的版本?看这里 昵称： GreenForestQuan 2.技术的八荣八耻 linux(6) @fyjsnow 一般来说，模型的大小主要是指模型所包含的参数数量以及这些参数所占用的内存空间等，而占用磁盘空间则涉及到更多因素，以下是对它们关系的理解以及对所举例子中差异情况的分析： 模型大小与占用... --GreenForestQuan --fyjsnow --GreenForestQuan', 'DeepSeek-R1本地部署如何选择适合你的版本?看这里-腾讯云开发者社区-腾讯云 DeepSeek-R1本地部署如何选择适合你的版本?看这里 登录/注册 文章/答案/技术大牛搜索 社区首页 >专栏 >DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署：选择最适合你的版本，轻松搞定！ DeepSeek-R1的不同类型及含义 DeepSeek-R1类型信息表格 显卡：中等性能显卡，如NVIDIA GTX 1650或RTX 2060。 内存：16GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 CPU：8核以上处理器，如Intel i9或AMD Ryzen 9。 显卡：NVIDIA RTX 3080或更强。 内存：64GB RAM。 显卡：NVIDIA RTX 3090、A100或V100显卡。 内存：128GB RAM。 内存：128GB RAM。 内存：至少512GB RAM。 1.5B (15亿参数) 7B (70亿参数) 8B (80亿参数) 与上一个版本的计算能力比较：相比7B，计算能力提升 14%，推理能力有所增强，但增幅较小。 与上一个版本的生成质量比较：相比7B，生成质量提升 20%，生成的文本更加自然、准确，适应更复杂的语境。 14B (140亿参数) 与上一个版本的计算能力比较：相比8B，计算能力提升 75%，能够处理更复杂的语境和任务。 与上一个版本的生成质量比较：相比8B，生成质量提升 30%，长篇生成更连贯、自然，文本质量大幅提升。 与上一个版本的计算能力比较：相比14B，计算能力提升 129%，可以处理更多复杂任务。 与上一个版本的生成质量比较：相比14B，生成质量提升 40%，文本质量接近人工水平，适合高级写作和深度理解。 与上一个版本的计算能力比较：相比32B，计算能力提升 119%，能够处理更加复杂的推理和生成任务。 与上一个版本的生成质量比较：相比32B，生成质量提升 50%，文本质量更加精细，几乎无明显错误，适用于创意和高精度任务。 与上一个版本的计算能力比较：相比70B，计算能力提升 860%，能够处理极为复杂的推理任务和大规模内容生成。 与上一个版本的生成质量比较：相比70B，生成质量提升 100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂的任务。 计算能力：从1.5B到671B，每个版本相对于前一个版本的计算能力都有显著提升，尤其是从 70B 到 671B，计算能力的大幅度提升说明了超大模型在推理复杂性上的巨大优势。 生成质量：生成质量从 1.5B 到 671B 逐步提升，每个新版本生成的文本更加自然、流畅，能够处理更复杂的上下文和细节。尤其是 70B 和 671B 版本的文本生成已经达到了极高水平，几乎可以媲美人工写作。 如有侵权，请联系 cloudcommunity@tencent.com 删除。 DeepSeek 如有侵权，请联系 cloudcommunity@tencent.com 删除。 DeepSeek #deepSeek 登录 后参与评论 文章 0获赞 0 高性能应用服务 高性能应用服务(Hyper Application Inventor，HAI)是一款面向AI、科学计算的GPU算力服务产品，提供即插即用的澎湃算力与常见环境。助力中小企业及开发者快速部署LLM、AI作画、数据科学等高性能应用，原生集成配套的开发工具与组件，大幅提高应用层的开发生产效率。 Copyright © 2013 - 2025 Tencent Cloud. Copyright © 2013 - 2025 Tencent Cloud. 登录 后参与评论']
[2025-02-22 22:57:20] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 22:57:28] INFO [RAGChat.agent_excute:79] 2,结束调用llms,共耗时8.495207071304321
[2025-02-22 22:57:30] INFO [RAGChat.online_search:59] online_search result:['DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法）-腾讯云开发者社区-腾讯云 AntDream DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） 关注作者 前往小程序，Get_更优_阅读体验！ 立即前往 腾讯云 开发者社区 文档建议反馈控制台 登录/注册 首页 学习 文章/答案/技术大牛搜索 AntDream 社区首页 >专栏 >DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） AntDream DeepSeek-R1系列模型是基于Transformer架构的大型语言模型，支持中英文双语处理。该系列模型通过不断优化算法和增加训练数据，逐步提升了模型的性能和适用性。 R1-35B R1-671B R1-13B R1-7B R1-7B 是最轻量化的版本，适合移动设备或边缘计算场景。 R1-13B 在性能和资源消耗之间找到了平衡，适合大多数企业级应用。 R1-35B 和 R1-671B 则分别针对高复杂度和超大规模任务设计，适合云计算和高性能计算环境。 R1-7B 的训练数据经过精简，专注于核心任务，适合对计算资源敏感的场景。 R1-35B 和 R1-671B 则引入了更多样化的数据集，尤其是多模态数据（如图像、音频等），使其能够处理更复杂的任务。 R1-7B 和 R1-13B 更适合对实时性要求较高的场景。 R1-35B 和 R1-671B 则更适合需要高精度和复杂推理的任务。 R1-7B 对硬件要求最低，适合个人开发者或小企业。 R1-671B 则需要高性能计算集群支持，适合大型企业或科研机构。 如果你的任务是简单的文本生成或对话交互，可以选择 R1-7B 或 R1-13B。 如果需要处理复杂推理或多模态任务，则建议选择 R1-35B 或 R1-671B。 如果你的设备配置较低（如消费级GPU），请选择 R1-7B。 如果你拥有高性能计算集群，则可以考虑 R1-671B。 R1-7B 和 R1-13B 的使用成本较低，适合预算有限的用户。 R1-35B 和 R1-671B 的成本较高，适合大型企业和科研机构。 DeepSeek-R1系列模型通过不同的参数量和优化方向，为各种场景提供了灵活的选择。以下是各版本的核心特点总结： 本文参与\xa0腾讯云自媒体同步曝光计划，分享自微信公众号。 原始发表：2025-02-07，如有侵权请联系\xa0cloudcommunity@tencent.com 删除 DeepSeek 本文分享自 AntDream 微信公众号，前往查看 如有侵权，请联系 cloudcommunity@tencent.com 删除。 本文参与\xa0腾讯云自媒体同步曝光计划\xa0 ，欢迎热爱写作的你一起参与！ DeepSeek 登录 后参与评论 文章 0获赞 0 高性能应用服务 高性能应用服务(Hyper Application Inventor，HAI)是一款面向AI、科学计算的GPU算力服务产品，提供即插即用的澎湃算力与常见环境。助力中小企业及开发者快速部署LLM、AI作画、数据科学等高性能应用，原生集成配套的开发工具与组件，大幅提高应用层的开发生产效率。 Copyright © 2013 - 2025 Tencent Cloud. 腾讯云 版权所有 Copyright © 2013 - 2025 Tencent Cloud. 腾讯云 版权所有 登录 后参与评论', '访问Ollam的模型库，您将发现多种DeepSeek-R1模型版本，包括1.5B、7B、14B、32B等。选择适合您电脑硬件配置的模型版本是非常重要的。 2.1 如何选择模型版本？', 'DeepSeek-R1本地部署如何选择适合你的版本?看这里 - kaizi1992 - 博客园 会员 周边 众包 新闻 博问 闪存 赞助商 Chat2DB 所有博客 当前博客 博客园 DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署：选择最适合你的版本，轻松搞定！ DeepSeek-R1的不同类型及含义 DeepSeek-R1有多个不同的类型，每个类型的名称后面跟着一个数字（比如1.5B、7B、14B等），这些数字代表模型的参数量。参数量直接决定了模型的计算能力和存储需求，数字越大，模型越强，但也需要更多的硬件资源。 DeepSeek-R1类型信息表格 显卡：中等性能显卡，如NVIDIA GTX 1650或RTX 2060。 内存：16GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 CPU：8核以上处理器，如Intel i9或AMD Ryzen 9。 显卡：NVIDIA RTX 3080或更强。 内存：64GB RAM。 显卡：NVIDIA RTX 3090、A100或V100显卡。 内存：128GB RAM。 显卡：NVIDIA A100、V100显卡，甚至需要多个显卡配置。 内存：128GB RAM。 显卡：NVIDIA A100或多个V100显卡，甚至需要集群支持。 内存：至少512GB RAM。 1.5B (15亿参数) 7B (70亿参数) 8B (80亿参数) 与上一个版本的计算能力比较：相比7B，计算能力提升 14%，推理能力有所增强，但增幅较小。 与上一个版本的生成质量比较：相比7B，生成质量提升 20%，生成的文本更加自然、准确，适应更复杂的语境。 14B (140亿参数) 与上一个版本的计算能力比较：相比8B，计算能力提升 75%，能够处理更复杂的语境和任务。 与上一个版本的生成质量比较：相比8B，生成质量提升 30%，长篇生成更连贯、自然，文本质量大幅提升。 32B (320亿参数) 与上一个版本的计算能力比较：相比14B，计算能力提升 129%，可以处理更多复杂任务。 与上一个版本的生成质量比较：相比14B，生成质量提升 40%，文本质量接近人工水平，适合高级写作和深度理解。 70B (700亿参数) 与上一个版本的计算能力比较：相比32B，计算能力提升 119%，能够处理更加复杂的推理和生成任务。 与上一个版本的生成质量比较：相比32B，生成质量提升 50%，文本质量更加精细，几乎无明显错误，适用于创意和高精度任务。 671B (6710亿参数) 与上一个版本的计算能力比较：相比70B，计算能力提升 860%，能够处理极为复杂的推理任务和大规模内容生成。 与上一个版本的生成质量比较：相比70B，生成质量提升 100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂的任务。 计算能力：从1.5B到671B，每个版本相对于前一个版本的计算能力都有显著提升，尤其是从 70B 到 671B，计算能力的大幅度提升说明了超大模型在推理复杂性上的巨大优势。 生成质量：生成质量从 1.5B 到 671B 逐步提升，每个新版本生成的文本更加自然、流畅，能够处理更复杂的上下文和细节。尤其是 70B 和 671B 版本的文本生成已经达到了极高水平，几乎可以媲美人工写作。 posted @ 2025-02-11 13:03\xa0 kaizi1992\xa0 阅读(3155)\xa0 评论(6)\xa0 编辑\xa0 收藏\xa0 举报 Copyright © 2025 kaizi1992', "DeepSeek-R1 发布，性能对标 OpenAI o1 正式版 | DeepSeek API Docs DeepSeek API 文档 DeepSeek Platform DeepSeek-R1 发布 2025/01/20 DeepSeek APP 发布 2025/01/15 DeepSeek-V3 发布 2024/12/26 DeepSeek-V2.5-1210 发布 2024/12/10 DeepSeek-R1-Lite 发布 2024/11/20 DeepSeek-V2.5 发布 2024/09/05 API 文档 推理模型 (deepseek-reasoner) DeepSeek-R1 发布 2025/01/20 DeepSeek-R1 发布，性能对标 OpenAI o1 正式版 今天，我们正式发布 DeepSeek-R1，并同步开源模型权重。 DeepSeek-R1 遵循 MIT License，允许用户通过蒸馏技术借助 R1 训练其他模型。 DeepSeek-R1 上线 API，对用户开放思维链输出，通过设置 model='deepseek-reasoner' 即可调用。 DeepSeek 官网与 App 即日起同步更新上线。 DeepSeek-R1 在后训练阶段大规模使用了强化学习技术，在仅有极少标注数据的情况下，极大提升了模型推理能力。在数学、代码、自然语言推理等任务上，性能比肩 OpenAI o1 正式版。 在此，我们将 DeepSeek-R1 训练技术全部公开，以期促进技术社区的充分交流与创新协作。 论文链接： https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf 我们在开源 DeepSeek-R1-Zero 和 DeepSeek-R1 两个 660B 模型的同时，通过 DeepSeek-R1 的输出，蒸馏了 6 个小模型开源给社区，其中 32B 和 70B 模型在多项能力上实现了对标 OpenAI o1-mini 的效果。 HuggingFace 链接： https://huggingface.co/deepseek-ai 登录DeepSeek官网或官方App，打开“深度思考”模式，即可调用最新版 DeepSeek-R1 完成各类推理任务。 DeepSeek-R1 API 服务定价为每百万输入 tokens 1 元（缓存命中）/ 4 元（缓存未命中），每百万输出 tokens 16 元。 详细的 API 调用指南请参考官方文档：\xa0 https://api-docs.deepseek.com/zh-cn/guides/reasoning_model 上一页 错误码下一页 DeepSeek APP Copyright © 2024 DeepSeek, Inc.", 'DeepSeek-R1本地部署如何选择适合你的版本?看这里-腾讯云开发者社区-腾讯云 DeepSeek-R1本地部署如何选择适合你的版本?看这里 登录/注册 文章/答案/技术大牛搜索 社区首页 >专栏 >DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署：选择最适合你的版本，轻松搞定！ DeepSeek-R1的不同类型及含义 DeepSeek-R1类型信息表格 显卡：中等性能显卡，如NVIDIA GTX 1650或RTX 2060。 内存：16GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 CPU：8核以上处理器，如Intel i9或AMD Ryzen 9。 显卡：NVIDIA RTX 3080或更强。 内存：64GB RAM。 显卡：NVIDIA RTX 3090、A100或V100显卡。 内存：128GB RAM。 内存：128GB RAM。 内存：至少512GB RAM。 1.5B (15亿参数) 7B (70亿参数) 8B (80亿参数) 与上一个版本的计算能力比较：相比7B，计算能力提升 14%，推理能力有所增强，但增幅较小。 与上一个版本的生成质量比较：相比7B，生成质量提升 20%，生成的文本更加自然、准确，适应更复杂的语境。 14B (140亿参数) 与上一个版本的计算能力比较：相比8B，计算能力提升 75%，能够处理更复杂的语境和任务。 与上一个版本的生成质量比较：相比8B，生成质量提升 30%，长篇生成更连贯、自然，文本质量大幅提升。 与上一个版本的计算能力比较：相比14B，计算能力提升 129%，可以处理更多复杂任务。 与上一个版本的生成质量比较：相比14B，生成质量提升 40%，文本质量接近人工水平，适合高级写作和深度理解。 与上一个版本的计算能力比较：相比32B，计算能力提升 119%，能够处理更加复杂的推理和生成任务。 与上一个版本的生成质量比较：相比32B，生成质量提升 50%，文本质量更加精细，几乎无明显错误，适用于创意和高精度任务。 与上一个版本的计算能力比较：相比70B，计算能力提升 860%，能够处理极为复杂的推理任务和大规模内容生成。 与上一个版本的生成质量比较：相比70B，生成质量提升 100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂的任务。 计算能力：从1.5B到671B，每个版本相对于前一个版本的计算能力都有显著提升，尤其是从 70B 到 671B，计算能力的大幅度提升说明了超大模型在推理复杂性上的巨大优势。 生成质量：生成质量从 1.5B 到 671B 逐步提升，每个新版本生成的文本更加自然、流畅，能够处理更复杂的上下文和细节。尤其是 70B 和 671B 版本的文本生成已经达到了极高水平，几乎可以媲美人工写作。 如有侵权，请联系 cloudcommunity@tencent.com 删除。 DeepSeek 如有侵权，请联系 cloudcommunity@tencent.com 删除。 DeepSeek #deepSeek 登录 后参与评论 文章 0获赞 0 高性能应用服务 高性能应用服务(Hyper Application Inventor，HAI)是一款面向AI、科学计算的GPU算力服务产品，提供即插即用的澎湃算力与常见环境。助力中小企业及开发者快速部署LLM、AI作画、数据科学等高性能应用，原生集成配套的开发工具与组件，大幅提高应用层的开发生产效率。 Copyright © 2013 - 2025 Tencent Cloud. Copyright © 2013 - 2025 Tencent Cloud. 登录 后参与评论']
[2025-02-22 22:57:30] INFO [RAGChat.agent_excute:74] 3,开始调用llms
[2025-02-22 22:57:41] INFO [RAGChat.agent_excute:79] 3,结束调用llms,共耗时10.762791395187378
[2025-02-22 22:57:43] INFO [RAGChat.online_search:59] online_search result:['DeepSeek R1 提供了多个不同版本，以适应不同的应用场景和技术需求。主要分为两个重要版本：R1 和V3。 R1 版本特点. R1 是最初', 'DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法）-腾讯云开发者社区-腾讯云 AntDream DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） 关注作者 前往小程序，Get_更优_阅读体验！ 立即前往 腾讯云 开发者社区 文档建议反馈控制台 登录/注册 首页 学习 文章/答案/技术大牛搜索 AntDream 社区首页 >专栏 >DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） AntDream DeepSeek-R1系列模型是基于Transformer架构的大型语言模型，支持中英文双语处理。该系列模型通过不断优化算法和增加训练数据，逐步提升了模型的性能和适用性。 R1-35B R1-671B R1-13B R1-7B R1-7B 是最轻量化的版本，适合移动设备或边缘计算场景。 R1-13B 在性能和资源消耗之间找到了平衡，适合大多数企业级应用。 R1-35B 和 R1-671B 则分别针对高复杂度和超大规模任务设计，适合云计算和高性能计算环境。 R1-7B 的训练数据经过精简，专注于核心任务，适合对计算资源敏感的场景。 R1-35B 和 R1-671B 则引入了更多样化的数据集，尤其是多模态数据（如图像、音频等），使其能够处理更复杂的任务。 R1-7B 和 R1-13B 更适合对实时性要求较高的场景。 R1-35B 和 R1-671B 则更适合需要高精度和复杂推理的任务。 R1-7B 对硬件要求最低，适合个人开发者或小企业。 R1-671B 则需要高性能计算集群支持，适合大型企业或科研机构。 如果你的任务是简单的文本生成或对话交互，可以选择 R1-7B 或 R1-13B。 如果需要处理复杂推理或多模态任务，则建议选择 R1-35B 或 R1-671B。 如果你的设备配置较低（如消费级GPU），请选择 R1-7B。 如果你拥有高性能计算集群，则可以考虑 R1-671B。 R1-7B 和 R1-13B 的使用成本较低，适合预算有限的用户。 R1-35B 和 R1-671B 的成本较高，适合大型企业和科研机构。 DeepSeek-R1系列模型通过不同的参数量和优化方向，为各种场景提供了灵活的选择。以下是各版本的核心特点总结： 本文参与\xa0腾讯云自媒体同步曝光计划，分享自微信公众号。 原始发表：2025-02-07，如有侵权请联系\xa0cloudcommunity@tencent.com 删除 DeepSeek 本文分享自 AntDream 微信公众号，前往查看 如有侵权，请联系 cloudcommunity@tencent.com 删除。 本文参与\xa0腾讯云自媒体同步曝光计划\xa0 ，欢迎热爱写作的你一起参与！ DeepSeek 登录 后参与评论 文章 0获赞 0 高性能应用服务 高性能应用服务(Hyper Application Inventor，HAI)是一款面向AI、科学计算的GPU算力服务产品，提供即插即用的澎湃算力与常见环境。助力中小企业及开发者快速部署LLM、AI作画、数据科学等高性能应用，原生集成配套的开发工具与组件，大幅提高应用层的开发生产效率。 Copyright © 2013 - 2025 Tencent Cloud. 腾讯云 版权所有 Copyright © 2013 - 2025 Tencent Cloud. 腾讯云 版权所有 登录 后参与评论', '### DeepSeek R1 不同版本对比及特性#### 版本概述DeepSeek R1 提供了多个不同版本，以适应不同的应用场景和技术需求。主要分为两个重要版本：R1 和V3。 ###', 'DeepSeek-R1本地部署如何选择适合你的版本?看这里 - kaizi1992 - 博客园 会员 周边 众包 新闻 博问 闪存 赞助商 Chat2DB 所有博客 当前博客 博客园 DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署：选择最适合你的版本，轻松搞定！ DeepSeek-R1的不同类型及含义 DeepSeek-R1有多个不同的类型，每个类型的名称后面跟着一个数字（比如1.5B、7B、14B等），这些数字代表模型的参数量。参数量直接决定了模型的计算能力和存储需求，数字越大，模型越强，但也需要更多的硬件资源。 DeepSeek-R1类型信息表格 显卡：中等性能显卡，如NVIDIA GTX 1650或RTX 2060。 内存：16GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 CPU：8核以上处理器，如Intel i9或AMD Ryzen 9。 显卡：NVIDIA RTX 3080或更强。 内存：64GB RAM。 显卡：NVIDIA RTX 3090、A100或V100显卡。 内存：128GB RAM。 显卡：NVIDIA A100、V100显卡，甚至需要多个显卡配置。 内存：128GB RAM。 显卡：NVIDIA A100或多个V100显卡，甚至需要集群支持。 内存：至少512GB RAM。 1.5B (15亿参数) 7B (70亿参数) 8B (80亿参数) 与上一个版本的计算能力比较：相比7B，计算能力提升 14%，推理能力有所增强，但增幅较小。 与上一个版本的生成质量比较：相比7B，生成质量提升 20%，生成的文本更加自然、准确，适应更复杂的语境。 14B (140亿参数) 与上一个版本的计算能力比较：相比8B，计算能力提升 75%，能够处理更复杂的语境和任务。 与上一个版本的生成质量比较：相比8B，生成质量提升 30%，长篇生成更连贯、自然，文本质量大幅提升。 32B (320亿参数) 与上一个版本的计算能力比较：相比14B，计算能力提升 129%，可以处理更多复杂任务。 与上一个版本的生成质量比较：相比14B，生成质量提升 40%，文本质量接近人工水平，适合高级写作和深度理解。 70B (700亿参数) 与上一个版本的计算能力比较：相比32B，计算能力提升 119%，能够处理更加复杂的推理和生成任务。 与上一个版本的生成质量比较：相比32B，生成质量提升 50%，文本质量更加精细，几乎无明显错误，适用于创意和高精度任务。 671B (6710亿参数) 与上一个版本的计算能力比较：相比70B，计算能力提升 860%，能够处理极为复杂的推理任务和大规模内容生成。 与上一个版本的生成质量比较：相比70B，生成质量提升 100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂的任务。 计算能力：从1.5B到671B，每个版本相对于前一个版本的计算能力都有显著提升，尤其是从 70B 到 671B，计算能力的大幅度提升说明了超大模型在推理复杂性上的巨大优势。 生成质量：生成质量从 1.5B 到 671B 逐步提升，每个新版本生成的文本更加自然、流畅，能够处理更复杂的上下文和细节。尤其是 70B 和 671B 版本的文本生成已经达到了极高水平，几乎可以媲美人工写作。 posted @ 2025-02-11 13:03\xa0 kaizi1992\xa0 阅读(3155)\xa0 评论(6)\xa0 编辑\xa0 收藏\xa0 举报 Copyright © 2025 kaizi1992', 'DeepSeek-R1 Release | DeepSeek API Docs DeepSeek API Docs DeepSeek Platform Your First API Call DeepSeek-R1 Release 2025/01/20 DeepSeek APP 2025/01/15 Introducing DeepSeek-V3 2024/12/26 DeepSeek-V2.5-1210 Release 2024/12/10 DeepSeek-R1-Lite Release 2024/11/20 DeepSeek-V2.5 Release 2024/09/05 Reasoning Model (deepseek-reasoner) DeepSeek-R1 Release 2025/01/20 DeepSeek-R1 Release Try DeepThink at chat.deepseek.com today! 🔬 Distilled from DeepSeek-R1, 6 small models fully open-sourced 🔄 DeepSeek-R1 is now MIT licensed for clear open access 🔓 Open for the community to leverage model weights & outputs 🛠️ DeepSeek-R1: Technical Highlights 📄 More details: https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf ⚙️ Use DeepSeek-R1 by setting model=deepseek-reasoner 💰 $0.14 / million input tokens (cache hit) 💰 $0.55 / million input tokens (cache miss) 💰 $2.19 / million output tokens 📖 API guide: https://api-docs.deepseek.com/guides/reasoning_model Previous Error CodesNext Introducing DeepSeek App']
[2025-02-22 22:57:43] INFO [RAGChat.agent_excute:74] 4,开始调用llms
[2025-02-22 22:57:55] INFO [RAGChat.agent_excute:79] 4,结束调用llms,共耗时11.998324394226074
[2025-02-22 22:57:57] INFO [RAGChat.online_search:59] online_search result:['DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法）-腾讯云开发者社区-腾讯云 AntDream DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） 关注作者 前往小程序，Get_更优_阅读体验！ 立即前往 腾讯云 开发者社区 文档建议反馈控制台 登录/注册 首页 学习 文章/答案/技术大牛搜索 AntDream 社区首页 >专栏 >DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） AntDream DeepSeek-R1系列模型是基于Transformer架构的大型语言模型，支持中英文双语处理。该系列模型通过不断优化算法和增加训练数据，逐步提升了模型的性能和适用性。 R1-35B R1-671B R1-13B R1-7B R1-7B 是最轻量化的版本，适合移动设备或边缘计算场景。 R1-13B 在性能和资源消耗之间找到了平衡，适合大多数企业级应用。 R1-35B 和 R1-671B 则分别针对高复杂度和超大规模任务设计，适合云计算和高性能计算环境。 R1-7B 的训练数据经过精简，专注于核心任务，适合对计算资源敏感的场景。 R1-35B 和 R1-671B 则引入了更多样化的数据集，尤其是多模态数据（如图像、音频等），使其能够处理更复杂的任务。 R1-7B 和 R1-13B 更适合对实时性要求较高的场景。 R1-35B 和 R1-671B 则更适合需要高精度和复杂推理的任务。 R1-7B 对硬件要求最低，适合个人开发者或小企业。 R1-671B 则需要高性能计算集群支持，适合大型企业或科研机构。 如果你的任务是简单的文本生成或对话交互，可以选择 R1-7B 或 R1-13B。 如果需要处理复杂推理或多模态任务，则建议选择 R1-35B 或 R1-671B。 如果你的设备配置较低（如消费级GPU），请选择 R1-7B。 如果你拥有高性能计算集群，则可以考虑 R1-671B。 R1-7B 和 R1-13B 的使用成本较低，适合预算有限的用户。 R1-35B 和 R1-671B 的成本较高，适合大型企业和科研机构。 DeepSeek-R1系列模型通过不同的参数量和优化方向，为各种场景提供了灵活的选择。以下是各版本的核心特点总结： 本文参与\xa0腾讯云自媒体同步曝光计划，分享自微信公众号。 原始发表：2025-02-07，如有侵权请联系\xa0cloudcommunity@tencent.com 删除 DeepSeek 本文分享自 AntDream 微信公众号，前往查看 如有侵权，请联系 cloudcommunity@tencent.com 删除。 本文参与\xa0腾讯云自媒体同步曝光计划\xa0 ，欢迎热爱写作的你一起参与！ DeepSeek 登录 后参与评论 文章 0获赞 0 高性能应用服务 高性能应用服务(Hyper Application Inventor，HAI)是一款面向AI、科学计算的GPU算力服务产品，提供即插即用的澎湃算力与常见环境。助力中小企业及开发者快速部署LLM、AI作画、数据科学等高性能应用，原生集成配套的开发工具与组件，大幅提高应用层的开发生产效率。 Copyright © 2013 - 2025 Tencent Cloud. 腾讯云 版权所有 Copyright © 2013 - 2025 Tencent Cloud. 腾讯云 版权所有 登录 后参与评论', '### DeepSeek R1 不同版本对比及特性#### 版本概述DeepSeek R1 提供了多个不同版本，以适应不同的应用场景和技术需求。主要分为两个重要版本：R1 和V3。 ###', '打开Ollama 模型库 ，你会看到丰富多样的DeepSeek-R1 模型版本，如1.5B、7B、32B 等。 ... 模型选择：从模型列表中选择与你本地部署的DeepSeek-R1 模型', 'DeepSeek-R1本地部署如何选择适合你的版本?看这里 - kaizi1992 - 博客园 会员 周边 众包 新闻 博问 闪存 赞助商 Chat2DB 所有博客 当前博客 博客园 DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署：选择最适合你的版本，轻松搞定！ DeepSeek-R1的不同类型及含义 DeepSeek-R1有多个不同的类型，每个类型的名称后面跟着一个数字（比如1.5B、7B、14B等），这些数字代表模型的参数量。参数量直接决定了模型的计算能力和存储需求，数字越大，模型越强，但也需要更多的硬件资源。 DeepSeek-R1类型信息表格 显卡：中等性能显卡，如NVIDIA GTX 1650或RTX 2060。 内存：16GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 CPU：8核以上处理器，如Intel i9或AMD Ryzen 9。 显卡：NVIDIA RTX 3080或更强。 内存：64GB RAM。 显卡：NVIDIA RTX 3090、A100或V100显卡。 内存：128GB RAM。 显卡：NVIDIA A100、V100显卡，甚至需要多个显卡配置。 内存：128GB RAM。 显卡：NVIDIA A100或多个V100显卡，甚至需要集群支持。 内存：至少512GB RAM。 1.5B (15亿参数) 7B (70亿参数) 8B (80亿参数) 与上一个版本的计算能力比较：相比7B，计算能力提升 14%，推理能力有所增强，但增幅较小。 与上一个版本的生成质量比较：相比7B，生成质量提升 20%，生成的文本更加自然、准确，适应更复杂的语境。 14B (140亿参数) 与上一个版本的计算能力比较：相比8B，计算能力提升 75%，能够处理更复杂的语境和任务。 与上一个版本的生成质量比较：相比8B，生成质量提升 30%，长篇生成更连贯、自然，文本质量大幅提升。 32B (320亿参数) 与上一个版本的计算能力比较：相比14B，计算能力提升 129%，可以处理更多复杂任务。 与上一个版本的生成质量比较：相比14B，生成质量提升 40%，文本质量接近人工水平，适合高级写作和深度理解。 70B (700亿参数) 与上一个版本的计算能力比较：相比32B，计算能力提升 119%，能够处理更加复杂的推理和生成任务。 与上一个版本的生成质量比较：相比32B，生成质量提升 50%，文本质量更加精细，几乎无明显错误，适用于创意和高精度任务。 671B (6710亿参数) 与上一个版本的计算能力比较：相比70B，计算能力提升 860%，能够处理极为复杂的推理任务和大规模内容生成。 与上一个版本的生成质量比较：相比70B，生成质量提升 100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂的任务。 计算能力：从1.5B到671B，每个版本相对于前一个版本的计算能力都有显著提升，尤其是从 70B 到 671B，计算能力的大幅度提升说明了超大模型在推理复杂性上的巨大优势。 生成质量：生成质量从 1.5B 到 671B 逐步提升，每个新版本生成的文本更加自然、流畅，能够处理更复杂的上下文和细节。尤其是 70B 和 671B 版本的文本生成已经达到了极高水平，几乎可以媲美人工写作。 posted @ 2025-02-11 13:03\xa0 kaizi1992\xa0 阅读(3155)\xa0 评论(6)\xa0 编辑\xa0 收藏\xa0 举报 Copyright © 2025 kaizi1992', 'DeepSeek-R1 Release | DeepSeek API Docs DeepSeek API Docs DeepSeek Platform Your First API Call DeepSeek-R1 Release 2025/01/20 DeepSeek APP 2025/01/15 Introducing DeepSeek-V3 2024/12/26 DeepSeek-V2.5-1210 Release 2024/12/10 DeepSeek-R1-Lite Release 2024/11/20 DeepSeek-V2.5 Release 2024/09/05 Reasoning Model (deepseek-reasoner) DeepSeek-R1 Release 2025/01/20 DeepSeek-R1 Release Try DeepThink at chat.deepseek.com today! 🔬 Distilled from DeepSeek-R1, 6 small models fully open-sourced 🔄 DeepSeek-R1 is now MIT licensed for clear open access 🔓 Open for the community to leverage model weights & outputs 🛠️ DeepSeek-R1: Technical Highlights 📄 More details: https://github.com/deepseek-ai/DeepSeek-R1/blob/main/DeepSeek_R1.pdf ⚙️ Use DeepSeek-R1 by setting model=deepseek-reasoner 💰 $0.14 / million input tokens (cache hit) 💰 $0.55 / million input tokens (cache miss) 💰 $2.19 / million output tokens 📖 API guide: https://api-docs.deepseek.com/guides/reasoning_model Previous Error CodesNext Introducing DeepSeek App']
[2025-02-22 22:57:57] INFO [RAGChat.agent_excute:74] 5,开始调用llms
[2025-02-22 22:58:10] INFO [RAGChat.agent_excute:79] 5,结束调用llms,共耗时12.768584489822388
[2025-02-22 22:58:12] INFO [RAGChat.online_search:59] online_search result:['DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法）-腾讯云开发者社区-腾讯云 AntDream DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） 关注作者 前往小程序，Get_更优_阅读体验！ 立即前往 腾讯云 开发者社区 文档建议反馈控制台 登录/注册 首页 学习 文章/答案/技术大牛搜索 AntDream 社区首页 >专栏 >DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） DeepSeek R1模型全解析，90%的人都不知道的各版本区别（文末附免费流畅使用方法） AntDream DeepSeek-R1系列模型是基于Transformer架构的大型语言模型，支持中英文双语处理。该系列模型通过不断优化算法和增加训练数据，逐步提升了模型的性能和适用性。 R1-35B R1-671B R1-13B R1-7B R1-7B 是最轻量化的版本，适合移动设备或边缘计算场景。 R1-13B 在性能和资源消耗之间找到了平衡，适合大多数企业级应用。 R1-35B 和 R1-671B 则分别针对高复杂度和超大规模任务设计，适合云计算和高性能计算环境。 R1-7B 的训练数据经过精简，专注于核心任务，适合对计算资源敏感的场景。 R1-35B 和 R1-671B 则引入了更多样化的数据集，尤其是多模态数据（如图像、音频等），使其能够处理更复杂的任务。 R1-7B 和 R1-13B 更适合对实时性要求较高的场景。 R1-35B 和 R1-671B 则更适合需要高精度和复杂推理的任务。 R1-7B 对硬件要求最低，适合个人开发者或小企业。 R1-671B 则需要高性能计算集群支持，适合大型企业或科研机构。 如果你的任务是简单的文本生成或对话交互，可以选择 R1-7B 或 R1-13B。 如果需要处理复杂推理或多模态任务，则建议选择 R1-35B 或 R1-671B。 如果你的设备配置较低（如消费级GPU），请选择 R1-7B。 如果你拥有高性能计算集群，则可以考虑 R1-671B。 R1-7B 和 R1-13B 的使用成本较低，适合预算有限的用户。 R1-35B 和 R1-671B 的成本较高，适合大型企业和科研机构。 DeepSeek-R1系列模型通过不同的参数量和优化方向，为各种场景提供了灵活的选择。以下是各版本的核心特点总结： 本文参与\xa0腾讯云自媒体同步曝光计划，分享自微信公众号。 原始发表：2025-02-07，如有侵权请联系\xa0cloudcommunity@tencent.com 删除 DeepSeek 本文分享自 AntDream 微信公众号，前往查看 如有侵权，请联系 cloudcommunity@tencent.com 删除。 本文参与\xa0腾讯云自媒体同步曝光计划\xa0 ，欢迎热爱写作的你一起参与！ DeepSeek 登录 后参与评论 文章 0获赞 0 高性能应用服务 高性能应用服务(Hyper Application Inventor，HAI)是一款面向AI、科学计算的GPU算力服务产品，提供即插即用的澎湃算力与常见环境。助力中小企业及开发者快速部署LLM、AI作画、数据科学等高性能应用，原生集成配套的开发工具与组件，大幅提高应用层的开发生产效率。 Copyright © 2013 - 2025 Tencent Cloud. 腾讯云 版权所有 Copyright © 2013 - 2025 Tencent Cloud. 腾讯云 版权所有 登录 后参与评论', 'DeepSeek-R1和V3原版模型被俗称为“满血版”，正式代号一般被称为“DeepSeek-R1或V3 671B”版本。 其中“671B”为参数数量，而更高的参数数量意味着更智能化的AI', 'DeepSeek-R1本地部署如何选择适合你的版本?看这里 - kaizi1992 - 博客园 会员 周边 众包 新闻 博问 闪存 赞助商 Chat2DB 所有博客 当前博客 博客园 DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署：选择最适合你的版本，轻松搞定！ DeepSeek-R1的不同类型及含义 DeepSeek-R1有多个不同的类型，每个类型的名称后面跟着一个数字（比如1.5B、7B、14B等），这些数字代表模型的参数量。参数量直接决定了模型的计算能力和存储需求，数字越大，模型越强，但也需要更多的硬件资源。 DeepSeek-R1类型信息表格 显卡：中等性能显卡，如NVIDIA GTX 1650或RTX 2060。 内存：16GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 CPU：8核以上处理器，如Intel i9或AMD Ryzen 9。 显卡：NVIDIA RTX 3080或更强。 内存：64GB RAM。 显卡：NVIDIA RTX 3090、A100或V100显卡。 内存：128GB RAM。 显卡：NVIDIA A100、V100显卡，甚至需要多个显卡配置。 内存：128GB RAM。 显卡：NVIDIA A100或多个V100显卡，甚至需要集群支持。 内存：至少512GB RAM。 1.5B (15亿参数) 7B (70亿参数) 8B (80亿参数) 与上一个版本的计算能力比较：相比7B，计算能力提升 14%，推理能力有所增强，但增幅较小。 与上一个版本的生成质量比较：相比7B，生成质量提升 20%，生成的文本更加自然、准确，适应更复杂的语境。 14B (140亿参数) 与上一个版本的计算能力比较：相比8B，计算能力提升 75%，能够处理更复杂的语境和任务。 与上一个版本的生成质量比较：相比8B，生成质量提升 30%，长篇生成更连贯、自然，文本质量大幅提升。 32B (320亿参数) 与上一个版本的计算能力比较：相比14B，计算能力提升 129%，可以处理更多复杂任务。 与上一个版本的生成质量比较：相比14B，生成质量提升 40%，文本质量接近人工水平，适合高级写作和深度理解。 70B (700亿参数) 与上一个版本的计算能力比较：相比32B，计算能力提升 119%，能够处理更加复杂的推理和生成任务。 与上一个版本的生成质量比较：相比32B，生成质量提升 50%，文本质量更加精细，几乎无明显错误，适用于创意和高精度任务。 671B (6710亿参数) 与上一个版本的计算能力比较：相比70B，计算能力提升 860%，能够处理极为复杂的推理任务和大规模内容生成。 与上一个版本的生成质量比较：相比70B，生成质量提升 100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂的任务。 计算能力：从1.5B到671B，每个版本相对于前一个版本的计算能力都有显著提升，尤其是从 70B 到 671B，计算能力的大幅度提升说明了超大模型在推理复杂性上的巨大优势。 生成质量：生成质量从 1.5B 到 671B 逐步提升，每个新版本生成的文本更加自然、流畅，能够处理更复杂的上下文和细节。尤其是 70B 和 671B 版本的文本生成已经达到了极高水平，几乎可以媲美人工写作。 posted @ 2025-02-11 13:03\xa0 kaizi1992\xa0 阅读(3155)\xa0 评论(6)\xa0 编辑\xa0 收藏\xa0 举报 Copyright © 2025 kaizi1992', 'GreenForestQuan 模型版本    模型大小    CPU 显卡  内存  磁盘空间 1.5B    1.1GB   普通四核或六核处理器就行    NVIDIA GTX 1650或RTX 2060这种中等性能显卡    16GB RAM    至少50GB空闲空间 7B  4.7GB   6核或8核处理器    NVIDIA RTX 3060或更强的显卡   32GB RAM    至少100GB空闲空间 8B  4.9GB   6核或8核处理器    NVIDIA RTX 3060或更强的显卡   32GB RAM    至少100GB空闲空间 14B 9GB 8核以上处理器，像Intel i9或AMD Ryzen 9   NVIDIA RTX 3080或更强的显卡   64GB RAM    至少200GB空闲空间 32B 20GB    8核以上处理器 NVIDIA RTX 3090、A100或V100显卡 128GB RAM   至少500GB空闲空间 70B 43GB    12核以上处理器，推荐用高端Intel或AMD处理器  NVIDIA A100、V100显卡，可能还得多个显卡一起用  128GB RAM   至少1TB空闲空间 671B    404GB   高性能、多核CPU，建议多台服务器配置 NVIDIA A100或多个V100显卡，甚至需要集群支持   至少512GB RAM 至少2TB空闲空间 模型版本    主要功能    与上一版本计算能力比较 与上一版本生成质量比较 8B（80亿参数）   适用于高质量对话生成、短文本总结、复杂问题解答等    比7B计算能力提升14%，推理能力有增强，但增幅较小  比7B生成质量提升20%，生成文本更自然、准确，适应更复杂语境 14B（140亿参数） 用于高级语言理解、长篇文本生成、高级推理等任务 比8B计算能力提升75%，能处理更复杂语境和任务    比8B生成质量提升30%，长篇生成更连贯、自然，文本质量大幅提升 32B（320亿参数） 适合复杂推理任务、高级写作、长篇对话生成等   比14B计算能力提升129%，能处理更多复杂任务    比14B生成质量提升40%，文本质量接近人工水平，适合高级写作和深度理解 70B（700亿参数） 用于深度语义理解、创意写作、多模态推理等高端应用    比32B计算能力提升119%，能处理更复杂推理和生成任务    比32B生成质量提升50%，文本质量更精细，几乎无明显错误，适用于创意和高精度任务 671B（6710亿参数）   用于超高精度推理、大规模内容生成、跨领域深度理解等任务 比70B计算能力提升860%，能处理极为复杂推理任务和大规模内容生成  比70B生成质量提升100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂任务 GreenForestQuan posted @ 2025-02-12 11:54\xa0 GreenForestQuan\xa0 阅读(1010)\xa0 评论(2)\xa0 编辑\xa0 收藏\xa0 举报 DeepSeek-R1本地部署如何选择适合你的版本?看这里 · DeepSeek-R1本地部署如何选择适合你的版本?看这里 昵称： GreenForestQuan 2.技术的八荣八耻 linux(6) @fyjsnow 一般来说，模型的大小主要是指模型所包含的参数数量以及这些参数所占用的内存空间等，而占用磁盘空间则涉及到更多因素，以下是对它们关系的理解以及对所举例子中差异情况的分析： 模型大小与占用... --GreenForestQuan --fyjsnow --GreenForestQuan', 'DeepSeek-R1本地部署如何选择适合你的版本?看这里-腾讯云开发者社区-腾讯云 DeepSeek-R1本地部署如何选择适合你的版本?看这里 登录/注册 文章/答案/技术大牛搜索 社区首页 >专栏 >DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署如何选择适合你的版本?看这里 DeepSeek-R1本地部署：选择最适合你的版本，轻松搞定！ DeepSeek-R1的不同类型及含义 DeepSeek-R1类型信息表格 显卡：中等性能显卡，如NVIDIA GTX 1650或RTX 2060。 内存：16GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 显卡：NVIDIA RTX 3060或更强显卡。 内存：32GB RAM。 CPU：8核以上处理器，如Intel i9或AMD Ryzen 9。 显卡：NVIDIA RTX 3080或更强。 内存：64GB RAM。 显卡：NVIDIA RTX 3090、A100或V100显卡。 内存：128GB RAM。 内存：128GB RAM。 内存：至少512GB RAM。 1.5B (15亿参数) 7B (70亿参数) 8B (80亿参数) 与上一个版本的计算能力比较：相比7B，计算能力提升 14%，推理能力有所增强，但增幅较小。 与上一个版本的生成质量比较：相比7B，生成质量提升 20%，生成的文本更加自然、准确，适应更复杂的语境。 14B (140亿参数) 与上一个版本的计算能力比较：相比8B，计算能力提升 75%，能够处理更复杂的语境和任务。 与上一个版本的生成质量比较：相比8B，生成质量提升 30%，长篇生成更连贯、自然，文本质量大幅提升。 与上一个版本的计算能力比较：相比14B，计算能力提升 129%，可以处理更多复杂任务。 与上一个版本的生成质量比较：相比14B，生成质量提升 40%，文本质量接近人工水平，适合高级写作和深度理解。 与上一个版本的计算能力比较：相比32B，计算能力提升 119%，能够处理更加复杂的推理和生成任务。 与上一个版本的生成质量比较：相比32B，生成质量提升 50%，文本质量更加精细，几乎无明显错误，适用于创意和高精度任务。 与上一个版本的计算能力比较：相比70B，计算能力提升 860%，能够处理极为复杂的推理任务和大规模内容生成。 与上一个版本的生成质量比较：相比70B，生成质量提升 100%，文本生成几乎完美，几乎没有语境偏差，适用于最复杂的任务。 计算能力：从1.5B到671B，每个版本相对于前一个版本的计算能力都有显著提升，尤其是从 70B 到 671B，计算能力的大幅度提升说明了超大模型在推理复杂性上的巨大优势。 生成质量：生成质量从 1.5B 到 671B 逐步提升，每个新版本生成的文本更加自然、流畅，能够处理更复杂的上下文和细节。尤其是 70B 和 671B 版本的文本生成已经达到了极高水平，几乎可以媲美人工写作。 如有侵权，请联系 cloudcommunity@tencent.com 删除。 DeepSeek 如有侵权，请联系 cloudcommunity@tencent.com 删除。 DeepSeek #deepSeek 登录 后参与评论 文章 0获赞 0 高性能应用服务 高性能应用服务(Hyper Application Inventor，HAI)是一款面向AI、科学计算的GPU算力服务产品，提供即插即用的澎湃算力与常见环境。助力中小企业及开发者快速部署LLM、AI作画、数据科学等高性能应用，原生集成配套的开发工具与组件，大幅提高应用层的开发生产效率。 Copyright © 2013 - 2025 Tencent Cloud. Copyright © 2013 - 2025 Tencent Cloud. 登录 后参与评论']
[2025-02-22 22:58:12] INFO [RAGChat.agent_excute:74] 6,开始调用llms
[2025-02-22 22:58:30] INFO [RAGChat.agent_excute:79] 6,结束调用llms,共耗时17.82545566558838
[2025-02-22 22:58:30] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 22:58:30] INFO [RAGChat.agent_excute:74] 7,开始调用llms
[2025-02-22 22:58:44] INFO [RAGChat.agent_excute:79] 7,结束调用llms,共耗时13.975047588348389
[2025-02-22 22:58:44] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 22:58:44] INFO [RAGChat.agent_excute:74] 8,开始调用llms
[2025-02-22 23:00:58] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 23:01:20] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 23:01:24] INFO [RAGChat.agent_excute:79] 1,结束调用llms,共耗时4.5521416664123535
[2025-02-22 23:01:27] INFO [RAGChat.online_search:59] online_search result:['11度-17度。阴转阴，天气偏凉了，墨迹天气建议您穿上厚些的外套或是保暖的羊毛衫，年老体弱者可以选择保暖的摇粒绒外套。', '... 厦门天气栏目提供厦门天气预报、厦门市天气、厦门 ... 厦门明天天气. 白天. 小雨. 最高：30℃. 夜间. 阴. 最低：25℃. 移动版 | 电脑版 | 意见', '全国天气网 首页 国内天气 空气质量 国际天气 景点天气 天气新闻 专业天气 收藏 厦门[切换]当前时间：2025-02-14周五23:12 空气 优东风 3级 今天 (02-14) 多云 13/19℃ 持续无风向 微风 明天 (02-15) 多云 14/22℃ 持续无风向 微风 周日 (02-16) 多云转晴 13/21℃ 东风 3-5级 周一 (02-17) 晴转多云 11/20℃ 东北风 3-5级 周二 (02-18) 多云转晴 11/18℃ 东风 3-5级 周三 (02-19) 晴转多云 12/19℃ 东风 3-5级 周四 (02-20) 多云转阴 12/20℃ 持续无风向 微风 周五 (02-21) 阴转多云 11/17℃ 东北风 3-5级 周六 (02-22) 11/17℃ 东北风 4-5级 周日 (02-23) 阴转晴 11/15℃ 东北风 3-5级 周一 (02-24) 10/15℃ 东北风 5-6级 周二 (02-25) 11/16℃ 东风 3-5级 周三 (02-26) 12/19℃ 东南风 微风 周四 (02-27) 小雨 14/17℃ 西风 微风 周五 (02-28) 小雨转阴 14/18℃ 东风 微风 45日天气 15日天气 今日天气明日天气 天气：晴 13℃ 东风 3级 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风', '主站首页 领导主站 部门概况 新闻资讯 信息公开 服务办事 天气预报 首页 天气实况 气象公报 气象预警 城市预报 天气资讯 气象专题 气象科普 首页 国内 福建 厦门 国内  福建  厦门  更新 7天天气预报（2025/02/14 20:00发布） 星期五 多云 东北风 微风 19℃ 13℃ 多云 东北风 微风 星期六 多云 东南风 微风 22℃ 14℃ 多云 东风 微风 星期日 多云 东风 3~4级 21℃ 13℃ 东北风 3~4级 星期一 东北风 3~4级 20℃ 11℃ 多云 东北风 3~4级 星期二 多云 东风 3~4级 18℃ 11℃ 东北风 3~4级 星期三 东风 3~4级 19℃ 12℃ 多云 无持续风向 微风 星期四 多云 无持续风向 微风 20℃ 13℃ 无持续风向 微风 时间 02:00   05:00   08:00   11:00   14:00   17:00   20:00   23:00 天气                            气温 13.6℃   13℃ 13.8℃   18.8℃   22℃ 19.9℃   16.8℃   15.4℃ 风向 东北风 西北风 西风  东北风 东南风 东南风 东南风 东北风 南方地区有较大范围雨雪天气 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程', '首页 天气 下载 资讯 关于墨迹 天气 中国 厦门市， 福建省， 中国  13  多云 今天21:54更新 Windows 下载 今天 多云 13° / 19° 多云 14° / 22° 东南风 2级 13° / 21° 30° 20° 10° 0° 29°  30° 20° 10° 0° 29°  不适宜 猫咪 不适宜 运动 舒适 穿衣 适宜 划船 适宜 夜生活 舒适 舒适度 附近景点 更多 01 13/22° 02 12/19° 03 8/13° 04 7/16° 05 11/17° 东南风\xa0\xa03级 06 12/16° 07 7/15° 08 5/12° 09 6/13° 10 10/16° 11 13/21° 东南风\xa0\xa02级 12 12/16° 东南风\xa0\xa02级 13 10/16° 14 13/19° 15 14/22° 东南风\xa0\xa02级 16 13/21° 17 11/20° 18 11/18° 19 12/19° 20 12/20° 21 11/17° 22 11/17° 23 11/15° 24 10/14° 25 11/17° 26 13/19° 东南风\xa0\xa02级 27 14/16° 28 15/17° pm2.5']
[2025-02-22 23:01:27] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 23:01:34] INFO [RAGChat.agent_excute:79] 2,结束调用llms,共耗时6.946812391281128
[2025-02-22 23:01:37] INFO [RAGChat.online_search:59] online_search result:['11度-17度。阴转阴，天气偏凉了，墨迹天气建议您穿上厚些的外套或是保暖的羊毛衫，年老体弱者可以选择保暖的摇粒绒外套。', '... 厦门天气栏目提供厦门天气预报、厦门市天气、厦门 ... 厦门明天天气. 白天. 小雨. 最高：30℃. 夜间. 阴. 最低：25℃. 移动版 | 电脑版 | 意见', '全国天气网 首页 国内天气 空气质量 国际天气 景点天气 天气新闻 专业天气 收藏 厦门[切换]当前时间：2025-02-14周五23:12 空气 优东风 3级 今天 (02-14) 多云 13/19℃ 持续无风向 微风 明天 (02-15) 多云 14/22℃ 持续无风向 微风 周日 (02-16) 多云转晴 13/21℃ 东风 3-5级 周一 (02-17) 晴转多云 11/20℃ 东北风 3-5级 周二 (02-18) 多云转晴 11/18℃ 东风 3-5级 周三 (02-19) 晴转多云 12/19℃ 东风 3-5级 周四 (02-20) 多云转阴 12/20℃ 持续无风向 微风 周五 (02-21) 阴转多云 11/17℃ 东北风 3-5级 周六 (02-22) 11/17℃ 东北风 4-5级 周日 (02-23) 阴转晴 11/15℃ 东北风 3-5级 周一 (02-24) 10/15℃ 东北风 5-6级 周二 (02-25) 11/16℃ 东风 3-5级 周三 (02-26) 12/19℃ 东南风 微风 周四 (02-27) 小雨 14/17℃ 西风 微风 周五 (02-28) 小雨转阴 14/18℃ 东风 微风 45日天气 15日天气 今日天气明日天气 天气：晴 13℃ 东风 3级 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风', '主站首页 领导主站 部门概况 新闻资讯 信息公开 服务办事 天气预报 首页 天气实况 气象公报 气象预警 城市预报 天气资讯 气象专题 气象科普 首页 国内 福建 厦门 国内  福建  厦门  更新 7天天气预报（2025/02/14 20:00发布） 星期五 多云 东北风 微风 19℃ 13℃ 多云 东北风 微风 星期六 多云 东南风 微风 22℃ 14℃ 多云 东风 微风 星期日 多云 东风 3~4级 21℃ 13℃ 东北风 3~4级 星期一 东北风 3~4级 20℃ 11℃ 多云 东北风 3~4级 星期二 多云 东风 3~4级 18℃ 11℃ 东北风 3~4级 星期三 东风 3~4级 19℃ 12℃ 多云 无持续风向 微风 星期四 多云 无持续风向 微风 20℃ 13℃ 无持续风向 微风 时间 02:00   05:00   08:00   11:00   14:00   17:00   20:00   23:00 天气                            气温 13.6℃   13℃ 13.8℃   18.8℃   22℃ 19.9℃   16.8℃   15.4℃ 风向 东北风 西北风 西风  东北风 东南风 东南风 东南风 东北风 南方地区有较大范围雨雪天气 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程', '首页 天气 下载 资讯 关于墨迹 天气 中国 厦门市， 福建省， 中国  13  多云 今天21:54更新 Windows 下载 今天 多云 13° / 19° 多云 14° / 22° 东南风 2级 13° / 21° 30° 20° 10° 0° 29°  30° 20° 10° 0° 29°  不适宜 猫咪 不适宜 运动 舒适 穿衣 适宜 划船 适宜 夜生活 舒适 舒适度 附近景点 更多 01 13/22° 02 12/19° 03 8/13° 04 7/16° 05 11/17° 东南风\xa0\xa03级 06 12/16° 07 7/15° 08 5/12° 09 6/13° 10 10/16° 11 13/21° 东南风\xa0\xa02级 12 12/16° 东南风\xa0\xa02级 13 10/16° 14 13/19° 15 14/22° 东南风\xa0\xa02级 16 13/21° 17 11/20° 18 11/18° 19 12/19° 20 12/20° 21 11/17° 22 11/17° 23 11/15° 24 10/14° 25 11/17° 26 13/19° 东南风\xa0\xa02级 27 14/16° 28 15/17° pm2.5']
[2025-02-22 23:01:37] INFO [RAGChat.agent_excute:74] 3,开始调用llms
[2025-02-22 23:01:44] INFO [RAGChat.agent_excute:79] 3,结束调用llms,共耗时6.96109938621521
[2025-02-22 23:01:46] INFO [RAGChat.online_search:59] online_search result:['全国天气网 首页 国内天气 空气质量 国际天气 景点天气 天气新闻 专业天气 收藏 厦门[切换]当前时间：2025-02-14周五23:12 空气 优东风 3级 今天 (02-14) 多云 13/19℃ 持续无风向 微风 明天 (02-15) 多云 14/22℃ 持续无风向 微风 周日 (02-16) 多云转晴 13/21℃ 东风 3-5级 周一 (02-17) 晴转多云 11/20℃ 东北风 3-5级 周二 (02-18) 多云转晴 11/18℃ 东风 3-5级 周三 (02-19) 晴转多云 12/19℃ 东风 3-5级 周四 (02-20) 多云转阴 12/20℃ 持续无风向 微风 周五 (02-21) 阴转多云 11/17℃ 东北风 3-5级 周六 (02-22) 11/17℃ 东北风 4-5级 周日 (02-23) 阴转晴 11/15℃ 东北风 3-5级 周一 (02-24) 10/15℃ 东北风 5-6级 周二 (02-25) 11/16℃ 东风 3-5级 周三 (02-26) 12/19℃ 东南风 微风 周四 (02-27) 小雨 14/17℃ 西风 微风 周五 (02-28) 小雨转阴 14/18℃ 东风 微风 45日天气 15日天气 今日天气明日天气 天气：晴 13℃ 东风 3级 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风', '... 厦门天气栏目提供厦门天气预报、厦门市天气、厦门 ... 厦门明天天气. 白天. 小雨. 最高：30℃. 夜间. 阴. 最低：25℃. 移动版 | 电脑版', '主站首页 领导主站 部门概况 新闻资讯 信息公开 服务办事 天气预报 首页 天气实况 气象公报 气象预警 城市预报 天气资讯 气象专题 气象科普 首页 国内 福建 厦门 国内  福建  厦门  更新 7天天气预报（2025/02/14 20:00发布） 星期五 多云 东北风 微风 19℃ 13℃ 多云 东北风 微风 星期六 多云 东南风 微风 22℃ 14℃ 多云 东风 微风 星期日 多云 东风 3~4级 21℃ 13℃ 东北风 3~4级 星期一 东北风 3~4级 20℃ 11℃ 多云 东北风 3~4级 星期二 多云 东风 3~4级 18℃ 11℃ 东北风 3~4级 星期三 东风 3~4级 19℃ 12℃ 多云 无持续风向 微风 星期四 多云 无持续风向 微风 20℃ 13℃ 无持续风向 微风 时间 02:00   05:00   08:00   11:00   14:00   17:00   20:00   23:00 天气                            气温 13.6℃   13℃ 13.8℃   18.8℃   22℃ 19.9℃   16.8℃   15.4℃ 风向 东北风 西北风 西风  东北风 东南风 东南风 东南风 东北风 南方地区有较大范围雨雪天气 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程', '首页 天气 下载 资讯 关于墨迹 天气 中国 厦门市， 福建省， 中国  13  多云 今天21:54更新 Windows 下载 今天 多云 13° / 19° 多云 14° / 22° 东南风 2级 13° / 21° 30° 20° 10° 0° 29°  30° 20° 10° 0° 29°  不适宜 猫咪 不适宜 运动 舒适 穿衣 适宜 划船 适宜 夜生活 舒适 舒适度 附近景点 更多 01 13/22° 02 12/19° 03 8/13° 04 7/16° 05 11/17° 东南风\xa0\xa03级 06 12/16° 07 7/15° 08 5/12° 09 6/13° 10 10/16° 11 13/21° 东南风\xa0\xa02级 12 12/16° 东南风\xa0\xa02级 13 10/16° 14 13/19° 15 14/22° 东南风\xa0\xa02级 16 13/21° 17 11/20° 18 11/18° 19 12/19° 20 12/20° 21 11/17° 22 11/17° 23 11/15° 24 10/14° 25 11/17° 26 13/19° 东南风\xa0\xa02级 27 14/16° 28 15/17° pm2.5', '【厦门天气预报】最新实时天气，厦门旅游指数/交通指数，24小时/未来天气预报查询 - 飞猪天气 搜索 我的订单 注册 登录 飞猪国际 联系我们 机票 酒店 火车票 旅游度假 2025年1月4日 星期六 农历腊月初五最近更新: 15:17 10℃最低 10℃ - 最高 19℃ 风速：15km/h 2025年1月4日 星期六 农历腊月初五最近更新: 15:17 10℃最低 10℃ - 最高 19℃ 风速：15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 体感: 13℃ 石兜水库 5分超棒 厦门东坪山旅游度假区 4.9分超棒 1月3日 (今天) 最低 10℃ - 最高 19℃ 1月4日 (星期六) 最低 10℃ - 最高 20℃ 1月5日 (星期天) 最低 10℃ - 最高 20℃ 1月6日 (星期一) 最低 10℃ - 最高 17℃ 1月7日 (星期二) 最低 10℃ - 最高 18℃ 漳州8℃ - 19℃ 泉州10℃ - 17℃ 龙岩4℃ - 20℃ 莆田11℃ - 17℃ 潮州9℃ - 20℃ 汕头12℃ - 20℃ 合肥南站(出口)天气 1990小郡肝串串香(临江店)天气 绝味鸭脖(泌阳行政路店)天气 爱尚花海主题乐园(爱尚庄园)天气']
[2025-02-22 23:01:46] INFO [RAGChat.agent_excute:74] 4,开始调用llms
[2025-02-22 23:01:53] INFO [RAGChat.agent_excute:79] 4,结束调用llms,共耗时7.277256488800049
[2025-02-22 23:01:57] INFO [RAGChat.online_search:59] online_search result:['全国天气网 首页 国内天气 空气质量 国际天气 景点天气 天气新闻 专业天气 收藏 厦门[切换]当前时间：2025-02-14周五23:12 空气 优东风 3级 今天 (02-14) 多云 13/19℃ 持续无风向 微风 明天 (02-15) 多云 14/22℃ 持续无风向 微风 周日 (02-16) 多云转晴 13/21℃ 东风 3-5级 周一 (02-17) 晴转多云 11/20℃ 东北风 3-5级 周二 (02-18) 多云转晴 11/18℃ 东风 3-5级 周三 (02-19) 晴转多云 12/19℃ 东风 3-5级 周四 (02-20) 多云转阴 12/20℃ 持续无风向 微风 周五 (02-21) 阴转多云 11/17℃ 东北风 3-5级 周六 (02-22) 11/17℃ 东北风 4-5级 周日 (02-23) 阴转晴 11/15℃ 东北风 3-5级 周一 (02-24) 10/15℃ 东北风 5-6级 周二 (02-25) 11/16℃ 东风 3-5级 周三 (02-26) 12/19℃ 东南风 微风 周四 (02-27) 小雨 14/17℃ 西风 微风 周五 (02-28) 小雨转阴 14/18℃ 东风 微风 45日天气 15日天气 今日天气明日天气 天气：晴 13℃ 东风 3级 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风', '... 厦门天气栏目提供厦门天气预报、厦门市天气、厦门 ... 厦门明天天气. 白天. 小雨. 最高：30℃. 夜间. 阴. 最低：25℃. 移动版 | 电脑版', '主站首页 领导主站 部门概况 新闻资讯 信息公开 服务办事 天气预报 首页 天气实况 气象公报 气象预警 城市预报 天气资讯 气象专题 气象科普 首页 国内 福建 厦门 国内  福建  厦门  更新 7天天气预报（2025/02/14 20:00发布） 星期五 多云 东北风 微风 19℃ 13℃ 多云 东北风 微风 星期六 多云 东南风 微风 22℃ 14℃ 多云 东风 微风 星期日 多云 东风 3~4级 21℃ 13℃ 东北风 3~4级 星期一 东北风 3~4级 20℃ 11℃ 多云 东北风 3~4级 星期二 多云 东风 3~4级 18℃ 11℃ 东北风 3~4级 星期三 东风 3~4级 19℃ 12℃ 多云 无持续风向 微风 星期四 多云 无持续风向 微风 20℃ 13℃ 无持续风向 微风 时间 02:00   05:00   08:00   11:00   14:00   17:00   20:00   23:00 天气                            气温 13.6℃   13℃ 13.8℃   18.8℃   22℃ 19.9℃   16.8℃   15.4℃ 风向 东北风 西北风 西风  东北风 东南风 东南风 东南风 东北风 南方地区有较大范围雨雪天气 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程', '首页 天气 下载 资讯 关于墨迹 天气 中国 厦门市， 福建省， 中国  13  多云 今天21:54更新 Windows 下载 今天 多云 13° / 19° 多云 14° / 22° 东南风 2级 13° / 21° 30° 20° 10° 0° 29°  30° 20° 10° 0° 29°  不适宜 猫咪 不适宜 运动 舒适 穿衣 适宜 划船 适宜 夜生活 舒适 舒适度 附近景点 更多 01 13/22° 02 12/19° 03 8/13° 04 7/16° 05 11/17° 东南风\xa0\xa03级 06 12/16° 07 7/15° 08 5/12° 09 6/13° 10 10/16° 11 13/21° 东南风\xa0\xa02级 12 12/16° 东南风\xa0\xa02级 13 10/16° 14 13/19° 15 14/22° 东南风\xa0\xa02级 16 13/21° 17 11/20° 18 11/18° 19 12/19° 20 12/20° 21 11/17° 22 11/17° 23 11/15° 24 10/14° 25 11/17° 26 13/19° 东南风\xa0\xa02级 27 14/16° 28 15/17° pm2.5', '【厦门天气预报】最新实时天气，厦门旅游指数/交通指数，24小时/未来天气预报查询 - 飞猪天气 搜索 我的订单 注册 登录 飞猪国际 联系我们 机票 酒店 火车票 旅游度假 2025年1月4日 星期六 农历腊月初五最近更新: 15:17 10℃最低 10℃ - 最高 19℃ 风速：15km/h 2025年1月4日 星期六 农历腊月初五最近更新: 15:17 10℃最低 10℃ - 最高 19℃ 风速：15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 体感: 13℃ 石兜水库 5分超棒 厦门东坪山旅游度假区 4.9分超棒 1月3日 (今天) 最低 10℃ - 最高 19℃ 1月4日 (星期六) 最低 10℃ - 最高 20℃ 1月5日 (星期天) 最低 10℃ - 最高 20℃ 1月6日 (星期一) 最低 10℃ - 最高 17℃ 1月7日 (星期二) 最低 10℃ - 最高 18℃ 漳州8℃ - 19℃ 泉州10℃ - 17℃ 龙岩4℃ - 20℃ 莆田11℃ - 17℃ 潮州9℃ - 20℃ 汕头12℃ - 20℃ 合肥南站(出口)天气 1990小郡肝串串香(临江店)天气 绝味鸭脖(泌阳行政路店)天气 爱尚花海主题乐园(爱尚庄园)天气']
[2025-02-22 23:01:57] INFO [RAGChat.agent_excute:74] 5,开始调用llms
[2025-02-22 23:02:04] INFO [RAGChat.agent_excute:79] 5,结束调用llms,共耗时6.973612546920776
[2025-02-22 23:08:21] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 23:08:34] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 23:08:39] INFO [RAGChat.agent_excute:79] 1,结束调用llms,共耗时4.739210605621338
[2025-02-22 23:08:40] INFO [RAGChat.online_search:59] online_search result:['11度-17度。阴转阴，天气偏凉了，墨迹天气建议您穿上厚些的外套或是保暖的羊毛衫，年老体弱者可以选择保暖的摇粒绒外套。', '... 厦门天气栏目提供厦门天气预报、厦门市天气、厦门 ... 厦门明天天气. 白天. 小雨. 最高：30℃. 夜间. 阴. 最低：25℃. 移动版 | 电脑版 | 意见', '全国天气网 首页 国内天气 空气质量 国际天气 景点天气 天气新闻 专业天气 收藏 厦门[切换]当前时间：2025-02-14周五23:12 空气 优东风 3级 今天 (02-14) 多云 13/19℃ 持续无风向 微风 明天 (02-15) 多云 14/22℃ 持续无风向 微风 周日 (02-16) 多云转晴 13/21℃ 东风 3-5级 周一 (02-17) 晴转多云 11/20℃ 东北风 3-5级 周二 (02-18) 多云转晴 11/18℃ 东风 3-5级 周三 (02-19) 晴转多云 12/19℃ 东风 3-5级 周四 (02-20) 多云转阴 12/20℃ 持续无风向 微风 周五 (02-21) 阴转多云 11/17℃ 东北风 3-5级 周六 (02-22) 11/17℃ 东北风 4-5级 周日 (02-23) 阴转晴 11/15℃ 东北风 3-5级 周一 (02-24) 10/15℃ 东北风 5-6级 周二 (02-25) 11/16℃ 东风 3-5级 周三 (02-26) 12/19℃ 东南风 微风 周四 (02-27) 小雨 14/17℃ 西风 微风 周五 (02-28) 小雨转阴 14/18℃ 东风 微风 45日天气 15日天气 今日天气明日天气 天气：晴 13℃ 东风 3级 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风', '主站首页 领导主站 部门概况 新闻资讯 信息公开 服务办事 天气预报 首页 天气实况 气象公报 气象预警 城市预报 天气资讯 气象专题 气象科普 首页 国内 福建 厦门 国内  福建  厦门  更新 7天天气预报（2025/02/14 20:00发布） 星期五 多云 东北风 微风 19℃ 13℃ 多云 东北风 微风 星期六 多云 东南风 微风 22℃ 14℃ 多云 东风 微风 星期日 多云 东风 3~4级 21℃ 13℃ 东北风 3~4级 星期一 东北风 3~4级 20℃ 11℃ 多云 东北风 3~4级 星期二 多云 东风 3~4级 18℃ 11℃ 东北风 3~4级 星期三 东风 3~4级 19℃ 12℃ 多云 无持续风向 微风 星期四 多云 无持续风向 微风 20℃ 13℃ 无持续风向 微风 时间 02:00   05:00   08:00   11:00   14:00   17:00   20:00   23:00 天气                            气温 13.6℃   13℃ 13.8℃   18.8℃   22℃ 19.9℃   16.8℃   15.4℃ 风向 东北风 西北风 西风  东北风 东南风 东南风 东南风 东北风 南方地区有较大范围雨雪天气 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程', '首页 天气 下载 资讯 关于墨迹 天气 中国 厦门市， 福建省， 中国  13  多云 今天21:54更新 Windows 下载 今天 多云 13° / 19° 多云 14° / 22° 东南风 2级 13° / 21° 30° 20° 10° 0° 29°  30° 20° 10° 0° 29°  不适宜 猫咪 不适宜 运动 舒适 穿衣 适宜 划船 适宜 夜生活 舒适 舒适度 附近景点 更多 01 13/22° 02 12/19° 03 8/13° 04 7/16° 05 11/17° 东南风\xa0\xa03级 06 12/16° 07 7/15° 08 5/12° 09 6/13° 10 10/16° 11 13/21° 东南风\xa0\xa02级 12 12/16° 东南风\xa0\xa02级 13 10/16° 14 13/19° 15 14/22° 东南风\xa0\xa02级 16 13/21° 17 11/20° 18 11/18° 19 12/19° 20 12/20° 21 11/17° 22 11/17° 23 11/15° 24 10/14° 25 11/17° 26 13/19° 东南风\xa0\xa02级 27 14/16° 28 15/17° pm2.5']
[2025-02-22 23:08:40] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 23:08:46] INFO [RAGChat.agent_excute:79] 2,结束调用llms,共耗时5.665140628814697
[2025-02-22 23:08:49] INFO [RAGChat.online_search:59] online_search result:['11度-17度。阴转阴，天气偏凉了，墨迹天气建议您穿上厚些的外套或是保暖的羊毛衫，年老体弱者可以选择保暖的摇粒绒外套。', '... 厦门天气栏目提供厦门天气预报、厦门市天气、厦门 ... 厦门明天天气. 白天. 小雨. 最高：30℃. 夜间. 阴. 最低：25℃. 移动版 | 电脑版 | 意见', '全国天气网 首页 国内天气 空气质量 国际天气 景点天气 天气新闻 专业天气 收藏 厦门[切换]当前时间：2025-02-14周五23:12 空气 优东风 3级 今天 (02-14) 多云 13/19℃ 持续无风向 微风 明天 (02-15) 多云 14/22℃ 持续无风向 微风 周日 (02-16) 多云转晴 13/21℃ 东风 3-5级 周一 (02-17) 晴转多云 11/20℃ 东北风 3-5级 周二 (02-18) 多云转晴 11/18℃ 东风 3-5级 周三 (02-19) 晴转多云 12/19℃ 东风 3-5级 周四 (02-20) 多云转阴 12/20℃ 持续无风向 微风 周五 (02-21) 阴转多云 11/17℃ 东北风 3-5级 周六 (02-22) 11/17℃ 东北风 4-5级 周日 (02-23) 阴转晴 11/15℃ 东北风 3-5级 周一 (02-24) 10/15℃ 东北风 5-6级 周二 (02-25) 11/16℃ 东风 3-5级 周三 (02-26) 12/19℃ 东南风 微风 周四 (02-27) 小雨 14/17℃ 西风 微风 周五 (02-28) 小雨转阴 14/18℃ 东风 微风 45日天气 15日天气 今日天气明日天气 天气：晴 13℃ 东风 3级 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风', '主站首页 领导主站 部门概况 新闻资讯 信息公开 服务办事 天气预报 首页 天气实况 气象公报 气象预警 城市预报 天气资讯 气象专题 气象科普 首页 国内 福建 厦门 国内  福建  厦门  更新 7天天气预报（2025/02/14 20:00发布） 星期五 多云 东北风 微风 19℃ 13℃ 多云 东北风 微风 星期六 多云 东南风 微风 22℃ 14℃ 多云 东风 微风 星期日 多云 东风 3~4级 21℃ 13℃ 东北风 3~4级 星期一 东北风 3~4级 20℃ 11℃ 多云 东北风 3~4级 星期二 多云 东风 3~4级 18℃ 11℃ 东北风 3~4级 星期三 东风 3~4级 19℃ 12℃ 多云 无持续风向 微风 星期四 多云 无持续风向 微风 20℃ 13℃ 无持续风向 微风 时间 02:00   05:00   08:00   11:00   14:00   17:00   20:00   23:00 天气                            气温 13.6℃   13℃ 13.8℃   18.8℃   22℃ 19.9℃   16.8℃   15.4℃ 风向 东北风 西北风 西风  东北风 东南风 东南风 东南风 东北风 南方地区有较大范围雨雪天气 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程', '首页 天气 下载 资讯 关于墨迹 天气 中国 厦门市， 福建省， 中国  13  多云 今天21:54更新 Windows 下载 今天 多云 13° / 19° 多云 14° / 22° 东南风 2级 13° / 21° 30° 20° 10° 0° 29°  30° 20° 10° 0° 29°  不适宜 猫咪 不适宜 运动 舒适 穿衣 适宜 划船 适宜 夜生活 舒适 舒适度 附近景点 更多 01 13/22° 02 12/19° 03 8/13° 04 7/16° 05 11/17° 东南风\xa0\xa03级 06 12/16° 07 7/15° 08 5/12° 09 6/13° 10 10/16° 11 13/21° 东南风\xa0\xa02级 12 12/16° 东南风\xa0\xa02级 13 10/16° 14 13/19° 15 14/22° 东南风\xa0\xa02级 16 13/21° 17 11/20° 18 11/18° 19 12/19° 20 12/20° 21 11/17° 22 11/17° 23 11/15° 24 10/14° 25 11/17° 26 13/19° 东南风\xa0\xa02级 27 14/16° 28 15/17° pm2.5']
[2025-02-22 23:08:49] INFO [RAGChat.agent_excute:74] 3,开始调用llms
[2025-02-22 23:08:56] INFO [RAGChat.agent_excute:79] 3,结束调用llms,共耗时6.939889907836914
[2025-02-22 23:08:58] INFO [RAGChat.online_search:59] online_search result:['... 厦门天气栏目提供厦门天气预报、厦门市天气、厦门 ... 厦门明天天气. 白天. 小雨. 最高：30℃. 夜间. 阴. 最低：25℃. 移动版 | 电脑版 | 意见', '11度-17度。阴转阴，天气偏凉了，墨迹天气建议您穿上厚些的外套或是保暖的羊毛衫，年老体弱者可以选择保暖的摇粒绒外套。', '全国天气网 首页 国内天气 空气质量 国际天气 景点天气 天气新闻 专业天气 收藏 厦门[切换]当前时间：2025-02-14周五23:12 空气 优东风 3级 今天 (02-14) 多云 13/19℃ 持续无风向 微风 明天 (02-15) 多云 14/22℃ 持续无风向 微风 周日 (02-16) 多云转晴 13/21℃ 东风 3-5级 周一 (02-17) 晴转多云 11/20℃ 东北风 3-5级 周二 (02-18) 多云转晴 11/18℃ 东风 3-5级 周三 (02-19) 晴转多云 12/19℃ 东风 3-5级 周四 (02-20) 多云转阴 12/20℃ 持续无风向 微风 周五 (02-21) 阴转多云 11/17℃ 东北风 3-5级 周六 (02-22) 11/17℃ 东北风 4-5级 周日 (02-23) 阴转晴 11/15℃ 东北风 3-5级 周一 (02-24) 10/15℃ 东北风 5-6级 周二 (02-25) 11/16℃ 东风 3-5级 周三 (02-26) 12/19℃ 东南风 微风 周四 (02-27) 小雨 14/17℃ 西风 微风 周五 (02-28) 小雨转阴 14/18℃ 东风 微风 45日天气 15日天气 今日天气明日天气 天气：晴 13℃ 东风 3级 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风', '主站首页 领导主站 部门概况 新闻资讯 信息公开 服务办事 天气预报 首页 天气实况 气象公报 气象预警 城市预报 天气资讯 气象专题 气象科普 首页 国内 福建 厦门 国内  福建  厦门  更新 7天天气预报（2025/02/14 20:00发布） 星期五 多云 东北风 微风 19℃ 13℃ 多云 东北风 微风 星期六 多云 东南风 微风 22℃ 14℃ 多云 东风 微风 星期日 多云 东风 3~4级 21℃ 13℃ 东北风 3~4级 星期一 东北风 3~4级 20℃ 11℃ 多云 东北风 3~4级 星期二 多云 东风 3~4级 18℃ 11℃ 东北风 3~4级 星期三 东风 3~4级 19℃ 12℃ 多云 无持续风向 微风 星期四 多云 无持续风向 微风 20℃ 13℃ 无持续风向 微风 时间 02:00   05:00   08:00   11:00   14:00   17:00   20:00   23:00 天气                            气温 13.6℃   13℃ 13.8℃   18.8℃   22℃ 19.9℃   16.8℃   15.4℃ 风向 东北风 西北风 西风  东北风 东南风 东南风 东南风 东北风 南方地区有较大范围雨雪天气 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程', '【厦门天气预报】最新实时天气，厦门旅游指数/交通指数，24小时/未来天气预报查询 - 飞猪天气 搜索 我的订单 注册 登录 飞猪国际 联系我们 机票 酒店 火车票 旅游度假 2025年1月4日 星期六 农历腊月初五最近更新: 15:17 10℃最低 10℃ - 最高 19℃ 风速：15km/h 2025年1月4日 星期六 农历腊月初五最近更新: 15:17 10℃最低 10℃ - 最高 19℃ 风速：15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 体感: 13℃ 石兜水库 5分超棒 厦门东坪山旅游度假区 4.9分超棒 1月3日 (今天) 最低 10℃ - 最高 19℃ 1月4日 (星期六) 最低 10℃ - 最高 20℃ 1月5日 (星期天) 最低 10℃ - 最高 20℃ 1月6日 (星期一) 最低 10℃ - 最高 17℃ 1月7日 (星期二) 最低 10℃ - 最高 18℃ 漳州8℃ - 19℃ 泉州10℃ - 17℃ 龙岩4℃ - 20℃ 莆田11℃ - 17℃ 潮州9℃ - 20℃ 汕头12℃ - 20℃ 合肥南站(出口)天气 1990小郡肝串串香(临江店)天气 绝味鸭脖(泌阳行政路店)天气 爱尚花海主题乐园(爱尚庄园)天气']
[2025-02-22 23:08:58] INFO [RAGChat.agent_excute:74] 4,开始调用llms
[2025-02-22 23:09:06] INFO [RAGChat.agent_excute:79] 4,结束调用llms,共耗时7.821600437164307
[2025-02-22 23:09:08] INFO [RAGChat.online_search:59] online_search result:['全国天气网 首页 国内天气 空气质量 国际天气 景点天气 天气新闻 专业天气 收藏 厦门[切换]当前时间：2025-02-14周五23:12 空气 优东风 3级 今天 (02-14) 多云 13/19℃ 持续无风向 微风 明天 (02-15) 多云 14/22℃ 持续无风向 微风 周日 (02-16) 多云转晴 13/21℃ 东风 3-5级 周一 (02-17) 晴转多云 11/20℃ 东北风 3-5级 周二 (02-18) 多云转晴 11/18℃ 东风 3-5级 周三 (02-19) 晴转多云 12/19℃ 东风 3-5级 周四 (02-20) 多云转阴 12/20℃ 持续无风向 微风 周五 (02-21) 阴转多云 11/17℃ 东北风 3-5级 周六 (02-22) 11/17℃ 东北风 4-5级 周日 (02-23) 阴转晴 11/15℃ 东北风 3-5级 周一 (02-24) 10/15℃ 东北风 5-6级 周二 (02-25) 11/16℃ 东风 3-5级 周三 (02-26) 12/19℃ 东南风 微风 周四 (02-27) 小雨 14/17℃ 西风 微风 周五 (02-28) 小雨转阴 14/18℃ 东风 微风 45日天气 15日天气 今日天气明日天气 天气：晴 13℃ 东风 3级 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风', '... 厦门天气栏目提供厦门天气预报、厦门市天气、厦门 ... 厦门明天天气. 白天. 小雨. 最高：30℃. 夜间. 阴. 最低：25℃. 移动版 | 电脑版', '主站首页 领导主站 部门概况 新闻资讯 信息公开 服务办事 天气预报 首页 天气实况 气象公报 气象预警 城市预报 天气资讯 气象专题 气象科普 首页 国内 福建 厦门 国内  福建  厦门  更新 7天天气预报（2025/02/14 20:00发布） 星期五 多云 东北风 微风 19℃ 13℃ 多云 东北风 微风 星期六 多云 东南风 微风 22℃ 14℃ 多云 东风 微风 星期日 多云 东风 3~4级 21℃ 13℃ 东北风 3~4级 星期一 东北风 3~4级 20℃ 11℃ 多云 东北风 3~4级 星期二 多云 东风 3~4级 18℃ 11℃ 东北风 3~4级 星期三 东风 3~4级 19℃ 12℃ 多云 无持续风向 微风 星期四 多云 无持续风向 微风 20℃ 13℃ 无持续风向 微风 时间 02:00   05:00   08:00   11:00   14:00   17:00   20:00   23:00 天气                            气温 13.6℃   13℃ 13.8℃   18.8℃   22℃ 19.9℃   16.8℃   15.4℃ 风向 东北风 西北风 西风  东北风 东南风 东南风 东南风 东北风 南方地区有较大范围雨雪天气 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程', '首页 天气 下载 资讯 关于墨迹 天气 中国 厦门市， 福建省， 中国  13  多云 今天21:54更新 Windows 下载 今天 多云 13° / 19° 多云 14° / 22° 东南风 2级 13° / 21° 30° 20° 10° 0° 29°  30° 20° 10° 0° 29°  不适宜 猫咪 不适宜 运动 舒适 穿衣 适宜 划船 适宜 夜生活 舒适 舒适度 附近景点 更多 01 13/22° 02 12/19° 03 8/13° 04 7/16° 05 11/17° 东南风\xa0\xa03级 06 12/16° 07 7/15° 08 5/12° 09 6/13° 10 10/16° 11 13/21° 东南风\xa0\xa02级 12 12/16° 东南风\xa0\xa02级 13 10/16° 14 13/19° 15 14/22° 东南风\xa0\xa02级 16 13/21° 17 11/20° 18 11/18° 19 12/19° 20 12/20° 21 11/17° 22 11/17° 23 11/15° 24 10/14° 25 11/17° 26 13/19° 东南风\xa0\xa02级 27 14/16° 28 15/17° pm2.5', '【厦门天气预报】最新实时天气，厦门旅游指数/交通指数，24小时/未来天气预报查询 - 飞猪天气 搜索 我的订单 注册 登录 飞猪国际 联系我们 机票 酒店 火车票 旅游度假 2025年1月4日 星期六 农历腊月初五最近更新: 15:17 10℃最低 10℃ - 最高 19℃ 风速：15km/h 2025年1月4日 星期六 农历腊月初五最近更新: 15:17 10℃最低 10℃ - 最高 19℃ 风速：15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 体感: 13℃ 石兜水库 5分超棒 厦门东坪山旅游度假区 4.9分超棒 1月3日 (今天) 最低 10℃ - 最高 19℃ 1月4日 (星期六) 最低 10℃ - 最高 20℃ 1月5日 (星期天) 最低 10℃ - 最高 20℃ 1月6日 (星期一) 最低 10℃ - 最高 17℃ 1月7日 (星期二) 最低 10℃ - 最高 18℃ 漳州8℃ - 19℃ 泉州10℃ - 17℃ 龙岩4℃ - 20℃ 莆田11℃ - 17℃ 潮州9℃ - 20℃ 汕头12℃ - 20℃ 合肥南站(出口)天气 1990小郡肝串串香(临江店)天气 绝味鸭脖(泌阳行政路店)天气 爱尚花海主题乐园(爱尚庄园)天气']
[2025-02-22 23:09:08] INFO [RAGChat.agent_excute:74] 5,开始调用llms
[2025-02-22 23:12:53] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 23:13:01] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 23:13:07] INFO [RAGChat.agent_excute:79] 1,结束调用llms,共耗时6.241119861602783
[2025-02-22 23:13:09] INFO [RAGChat.online_search:59] online_search result:['... 厦门天气栏目提供厦门天气预报、厦门市天气、厦门 ... 厦门明天天气. 白天. 小雨. 最高：30℃. 夜间. 阴. 最低：25℃. 移动版 | 电脑版 | 意见', '11度-17度。阴转阴，天气偏凉了，墨迹天气建议您穿上厚些的外套或是保暖的羊毛衫，年老体弱者可以选择保暖的摇粒绒外套。', '全国天气网 首页 国内天气 空气质量 国际天气 景点天气 天气新闻 专业天气 收藏 厦门[切换]当前时间：2025-02-14周五23:12 空气 优东风 3级 今天 (02-14) 多云 13/19℃ 持续无风向 微风 明天 (02-15) 多云 14/22℃ 持续无风向 微风 周日 (02-16) 多云转晴 13/21℃ 东风 3-5级 周一 (02-17) 晴转多云 11/20℃ 东北风 3-5级 周二 (02-18) 多云转晴 11/18℃ 东风 3-5级 周三 (02-19) 晴转多云 12/19℃ 东风 3-5级 周四 (02-20) 多云转阴 12/20℃ 持续无风向 微风 周五 (02-21) 阴转多云 11/17℃ 东北风 3-5级 周六 (02-22) 11/17℃ 东北风 4-5级 周日 (02-23) 阴转晴 11/15℃ 东北风 3-5级 周一 (02-24) 10/15℃ 东北风 5-6级 周二 (02-25) 11/16℃ 东风 3-5级 周三 (02-26) 12/19℃ 东南风 微风 周四 (02-27) 小雨 14/17℃ 西风 微风 周五 (02-28) 小雨转阴 14/18℃ 东风 微风 45日天气 15日天气 今日天气明日天气 天气：晴 13℃ 东风 3级 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风 持续无风向 微风', '主站首页 领导主站 部门概况 新闻资讯 信息公开 服务办事 天气预报 首页 天气实况 气象公报 气象预警 城市预报 天气资讯 气象专题 气象科普 首页 国内 福建 厦门 国内  福建  厦门  更新 7天天气预报（2025/02/14 20:00发布） 星期五 多云 东北风 微风 19℃ 13℃ 多云 东北风 微风 星期六 多云 东南风 微风 22℃ 14℃ 多云 东风 微风 星期日 多云 东风 3~4级 21℃ 13℃ 东北风 3~4级 星期一 东北风 3~4级 20℃ 11℃ 多云 东北风 3~4级 星期二 多云 东风 3~4级 18℃ 11℃ 东北风 3~4级 星期三 东风 3~4级 19℃ 12℃ 多云 无持续风向 微风 星期四 多云 无持续风向 微风 20℃ 13℃ 无持续风向 微风 时间 02:00   05:00   08:00   11:00   14:00   17:00   20:00   23:00 天气                            气温 13.6℃   13℃ 13.8℃   18.8℃   22℃ 19.9℃   16.8℃   15.4℃ 风向 东北风 西北风 西风  东北风 东南风 东南风 东南风 东北风 南方地区有较大范围雨雪天气 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程', '【厦门天气预报】最新实时天气，厦门旅游指数/交通指数，24小时/未来天气预报查询 - 飞猪天气 搜索 我的订单 注册 登录 飞猪国际 联系我们 机票 酒店 火车票 旅游度假 2025年1月4日 星期六 农历腊月初五最近更新: 15:17 10℃最低 10℃ - 最高 19℃ 风速：15km/h 2025年1月4日 星期六 农历腊月初五最近更新: 15:17 10℃最低 10℃ - 最高 19℃ 风速：15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 15km/h 体感: 13℃ 石兜水库 5分超棒 厦门东坪山旅游度假区 4.9分超棒 1月3日 (今天) 最低 10℃ - 最高 19℃ 1月4日 (星期六) 最低 10℃ - 最高 20℃ 1月5日 (星期天) 最低 10℃ - 最高 20℃ 1月6日 (星期一) 最低 10℃ - 最高 17℃ 1月7日 (星期二) 最低 10℃ - 最高 18℃ 漳州8℃ - 19℃ 泉州10℃ - 17℃ 龙岩4℃ - 20℃ 莆田11℃ - 17℃ 潮州9℃ - 20℃ 汕头12℃ - 20℃ 合肥南站(出口)天气 1990小郡肝串串香(临江店)天气 绝味鸭脖(泌阳行政路店)天气 爱尚花海主题乐园(爱尚庄园)天气']
[2025-02-22 23:13:09] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 23:13:21] INFO [RAGChat.agent_excute:79] 2,结束调用llms,共耗时11.600593566894531
[2025-02-22 23:13:21] INFO [RAGChat.agent_excute:113] 对于问题查询厦门明天天气的结果是：厦门明天（2025年2月15日）的天气预报为：白天多云，最高气温22℃；夜间多云，最低气温14℃。风向微风，持续无风向。
[2025-02-22 23:13:34] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 23:13:45] INFO [RAGChat.agent_excute:79] 1,结束调用llms,共耗时10.931539297103882
[2025-02-22 23:13:48] INFO [RAGChat.online_search:59] online_search result:['杭州市气象台2月20日19时50分发布的市区天气预报： 今天夜里阴有小到中雨，局部有雨夹雪；明天上午阴有时有小雨，局部小雨夹雪，下午起雨雪渐止转阴天；后天上午多云到', '杭州天气 __准确__及时__创新__奉献 浙江气象 杭州天气首页 气象预警 天气监测 天气预报 气象服务 气象科普 咨询建议 当前预警 更多 杭州市临平区气象台2025-02-08 15:00 发布低温橙色预警 + 详情 杭州市余杭区气象台2025-02-08 15:00 发布低温橙色预警 + 详情 杭州市临安区气象台2025-02-08 14:00 发布低温橙色预警 + 详情 主城区 萧山区 余杭区 临平区 富阳区 临安区 钱塘区 桐庐县 淳安县 建德市 杭州国家基准气候站发布 未获取到实时数据 --℃ 较昨日同期 持平  相对湿度： --% 风力： --气压： --hPa 近1小时降水: --mm 能见度： --m *实时数据、未经人工复核 2025年02月08日 07时15分 过去24小时 未来24小时 未来7天 _主城区_未来7天天气客观预报（该预报数据为数值预报自动输出，未经人工订正，仅供参考） 白天 08时_|_20时 夜晚 昨天20时_|_当天08时 _* 白天_为当天08时到20时，通常气温为最高温度； _夜晚_为昨天20时到当天08时，通常气温为最低温度。 天气头条 + 更多 【今天起较强冷空气影响 8-9日有较严重冰冻】   杭州气象微博 天气实况 0-3小时降水 雷达拼图 卫星云图 台风路径 详情 当前气温 今日最高气温 今日最低气温 过去1小时雨量 过去3小时雨量 过去12小时雨量 过去24小时雨量 当前风速 今日极大风 1小时降水 3小时降水 杭州市当前气温 分布图 气温(℃) 气象影视 + 更多 服务产品 环境气象 潮汐预报 云上科技馆 今日生活气象 2025-02-08 15:00 更新 2月9日杭州市区AQI:45-65，首要污染物:PM10，空气质量等级:优-良。空气质量可接受，某些污染物对极少数异常敏感人群健康可能有较弱影响。 2月10日杭州市区AQI:52-72，首要污染物:PM2.5和NO2，空气质量等级:良。 2月11日杭州市区AQI:50-70，首要污染物:PM2.5和NO2，空气质量等级:优-良。 明天2级 较适宜洗车。 明天3级 中等，属中等强度紫外线辐射天气，外出时建议涂擦SPF高于15、PA+的防晒护肤品，戴帽子、太阳镜。 明天2级 气象条件一般，请司机朋友们注意行车的安全。 明天4级 不适宜晨练。 明天1级 适宜穿严冬装。 明天4级 人体感觉很冷。 明天2级 较适宜晾晒。 杭州天气__为您着想__杭州天气__为您着想', '主站首页 领导主站 部门概况 新闻资讯 信息公开 服务办事 天气预报 首页 天气实况 气象公报 气象预警 城市预报 天气资讯 气象专题 气象科普 首页 国内 浙江 杭州 国内  浙江  杭州  更新 7天天气预报（2025/02/08 12:00发布） 星期六 北风 4~5级 2℃ -4℃ 北风 3~4级 星期日 东北风 3~4级 6℃ 0℃ 东北风 3~4级 星期一 东风 3~4级 11℃ 1℃ 多云 西南风 4~5级 星期二 多云 南风 4~5级 19℃ 4℃ 多云 北风 3~4级 星期三 小雨 北风 5~6级 13℃ 3℃ 小雨 北风 3~4级 星期四 多云 东风 3~4级 11℃ 3℃ 小雨 无持续风向 微风 星期五 小到中雨 东北风 4~5级 9℃ 4℃ 小到中雨 东北风 4~5级 时间 14:00   17:00   20:00   23:00   02:00   05:00   08:00   11:00 天气                            气温 1.7℃    2.5℃    -0.9℃   -2.6℃   -4.2℃   -3.9℃   -0.9℃   3.2℃ 风向 西北风 东北风 东北风 西北风 西北风 西北风 东北风 东北风 南方地区有较大范围雨雪天气 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程 琼州海峡等海域有大雾 中东部地区有较大范围雨雪过程', '全国天气网 首页 国内天气 空气质量 国际天气 景点天气 天气新闻 专业天气 收藏 杭州[切换]当前时间：2025-02-08周六15:30 空气 优西北风 2级 今天 (02-08) -4/2℃ 北风 4-5级 明天 (02-09) 0/6℃ 东北风 3-5级 周一 (02-10) 晴转多云 1/11℃ 东风 3-5级 周二 (02-11) 多云 4/19℃ 南风 4-5级 周三 (02-12) 小雨 3/13℃ 北风 5-6级 周四 (02-13) 多云转小雨 3/11℃ 东风 3-5级 周五 (02-14) 小到中雨 4/9℃ 东北风 4-5级 周六 (02-15) 小雨转阴 6/9℃ 西北风 微风 周日 (02-16) 3/15℃ 东北风 微风 周一 (02-17) 多云转阴 1/15℃ 东北风 微风 周二 (02-18) 2/10℃ 东风 微风 周三 (02-19) 5/16℃ 西北风 微风 周四 (02-20) 1/16℃ 西北风 微风 周五 (02-21) 多云转阴 3/15℃ 东北风 微风 周六 (02-22) 3/13℃ 东风 微风 45日天气 15日天气 天气：晴 3℃ 西北风 2级 北风 3-5级 北风 微风 北风 3-5级 北风 3-5级 北风 3-5级 北风 3-5级 东北风 3-5级 包头  兰州  杭州  吉林', '全国天气 15天天气 今天天气 明天天气 一周天气 40天天气 空气质量 历史天气 国际天气 天气资讯 万年历 景点天气 当前： 全国天气> 杭州天气预报15天 今天天气 明天天气 一周天气 15天天气 明天 02/09 晴 东北风 1级 优 周一 02/10 晴转多云 东风 1级 优 周二 02/11 多云 东南风 2级 优 周三 02/12 小雨 西北风 3级 优 周四 02/13 多云转小雨 东北风 2级 优 周五 02/14 小雨 东北风 3级 优 周一 02/17 多云转阴 东北风 2级 良 周二 02/18 阴 东风 1级 优 周三 02/19 阴 东北风 2级 优 周四 02/20 晴 东北风 3级 优 周五 02/21 多云转阴 北风 1级 优 周六 02/22 阴 西北风 4级 优 2月08日\xa0-4~2° 更多> 国际天气 历史天气 生活指数 更多> 02月08日 02月09日 02月10日 02月11日 02月12日 02月13日 02月14日 日历 更多> 全国天气 国际天气 历史天气 景点天气 万年历 天气资讯 空气质量 天气地图 手机网页版 手机APP官网 天气插件 XML地图 更正您的地理位置 意见反馈']
[2025-02-22 23:13:48] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 23:13:56] INFO [RAGChat.agent_excute:79] 2,结束调用llms,共耗时8.677692890167236
[2025-02-22 23:13:56] INFO [RAGChat.agent_excute:113] 对于问题杭州明天的天气的结果是：明天（2月9日），杭州的天气预报为：上午阴有时有小雨，局部小雨夹雪，下午起雨雪渐止转阴天。气温在0到6℃之间，东北风3-5级。
[2025-02-22 23:14:51] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 23:14:56] INFO [RAGChat.agent_excute:79] 1,结束调用llms,共耗时5.806019306182861
[2025-02-22 23:14:59] INFO [RAGChat.online_search:59] online_search result:['tomorrow 现在是一个Date对象，代表明天的日期。 时间没有改变--它仍然是你运行命令的时间，增加了24小时。 如果你还想把时间重置为"明天00:00:00"，你可以', '要获取明天的日期，您可以使用JavaScript 中的Date 对象和相关方法来实现。下面是获取明天日期的示例代码： var today = new Date(); // 获取当前日期和', '获取明天的日期字符串* @return */ public static String tomorrowDateStr(){ Date date=new Date();//取时间 Calendar calendar = Calendar.', '第1步：打开一个Excel表格，点击需要显示日期的单元格。第2步：在单元格中输入函数TODAY()或NOW()。第3步：按Enter键确认，单元格中会自动显示当前日期或时间。第4步：若要实现', '获取明天的日期. 类似地，要获取明天的日期也可以使用JS的Date对象结合一些方法进行计算。下面是获取明天日期的代码：']
[2025-02-22 23:14:59] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 23:15:07] INFO [RAGChat.agent_excute:79] 2,结束调用llms,共耗时8.848357200622559
[2025-02-22 23:15:07] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 23:15:07] INFO [RAGChat.agent_excute:74] 3,开始调用llms
[2025-02-22 23:15:15] INFO [RAGChat.agent_excute:79] 3,结束调用llms,共耗时7.090383768081665
[2025-02-22 23:15:15] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 23:15:15] INFO [RAGChat.agent_excute:74] 4,开始调用llms
[2025-02-22 23:15:22] INFO [RAGChat.agent_excute:79] 4,结束调用llms,共耗时7.079373121261597
[2025-02-22 23:15:22] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 23:15:22] INFO [RAGChat.agent_excute:74] 5,开始调用llms
[2025-02-22 23:15:28] INFO [RAGChat.agent_excute:79] 5,结束调用llms,共耗时6.766325950622559
[2025-02-22 23:15:28] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 23:15:28] INFO [RAGChat.agent_excute:74] 6,开始调用llms
[2025-02-22 23:15:37] INFO [RAGChat.agent_excute:79] 6,结束调用llms,共耗时8.891864776611328
[2025-02-22 23:15:37] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 23:15:37] INFO [RAGChat.agent_excute:74] 7,开始调用llms
[2025-02-22 23:15:46] INFO [RAGChat.agent_excute:79] 7,结束调用llms,共耗时8.905051469802856
[2025-02-22 23:15:46] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 23:15:46] INFO [RAGChat.agent_excute:74] 8,开始调用llms
[2025-02-22 23:17:03] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 23:17:13] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 23:17:18] INFO [RAGChat.agent_excute:79] 1,结束调用llms,共耗时4.742387056350708
[2025-02-22 23:17:21] INFO [RAGChat.online_search:59] online_search result:['tomorrow 现在是一个Date对象，代表明天的日期。 时间没有改变--它仍然是你运行命令的时间，增加了24小时。 如果你还想把时间重置为"明天00:00:00"，你可以', '要获取明天的日期，您可以使用JavaScript 中的Date 对象和相关方法来实现。下面是获取明天日期的示例代码： var today = new Date(); // 获取当前日期和', '获取明天的日期字符串* @return */ public static String tomorrowDateStr(){ Date date=new Date();//取时间 Calendar calendar = Calendar.', '第1步：打开一个Excel表格，点击需要显示日期的单元格。第2步：在单元格中输入函数TODAY()或NOW()。第3步：按Enter键确认，单元格中会自动显示当前日期或时间。第4步：若要实现', '获取明天的日期. 类似地，要获取明天的日期也可以使用JS的Date对象结合一些方法进行计算。下面是获取明天日期的代码：']
[2025-02-22 23:17:21] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 23:17:35] INFO [RAGChat.agent_excute:79] 2,结束调用llms,共耗时14.086565494537354
[2025-02-22 23:17:35] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 23:17:35] INFO [RAGChat.agent_excute:74] 3,开始调用llms
[2025-02-22 23:17:43] INFO [RAGChat.agent_excute:79] 3,结束调用llms,共耗时7.920914888381958
[2025-02-22 23:17:46] INFO [RAGChat.online_search:59] online_search result:['tomorrow 现在是一个Date对象，代表明天的日期。 时间没有改变--它仍然是你运行命令的时间，增加了24小时。 如果你还想把时间重置为"明天00:00:00"，你可以', '要获取明天的日期，您可以使用JavaScript 中的Date 对象和相关方法来实现。下面是获取明天日期的示例代码： var today = new Date(); // 获取当前日期和', '获取明天的日期字符串* @return */ public static String tomorrowDateStr(){ Date date=new Date();//取时间 Calendar calendar = Calendar.', '第1步：打开一个Excel表格，点击需要显示日期的单元格。第2步：在单元格中输入函数TODAY()或NOW()。第3步：按Enter键确认，单元格中会自动显示当前日期或时间。第4步：若要实现', '获取明天的日期. 类似地，要获取明天的日期也可以使用JS的Date对象结合一些方法进行计算。下面是获取明天日期的代码：']
[2025-02-22 23:17:46] INFO [RAGChat.agent_excute:74] 4,开始调用llms
[2025-02-22 23:18:27] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 23:18:35] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 23:18:46] INFO [RAGChat.agent_excute:79] 1,结束调用llms,共耗时11.216898202896118
[2025-02-22 23:18:46] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 23:18:59] INFO [RAGChat.agent_excute:79] 2,结束调用llms,共耗时12.854555130004883
[2025-02-22 23:18:59] ERROR [RAGChat.agent_excute:125] agent action call error: [Errno 2] No such file or directory: './data/llm_result\\./data/llm_result/finance_manual.md'
[2025-02-22 23:22:21] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 23:22:28] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 23:22:37] INFO [RAGChat.agent_excute:79] 1,结束调用llms,共耗时8.97566032409668
[2025-02-22 23:22:37] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 23:22:47] INFO [RAGChat.agent_excute:79] 2,结束调用llms,共耗时10.353809118270874
[2025-02-22 23:22:47] INFO [RAGChat.agent_excute:74] 3,开始调用llms
[2025-02-22 23:22:56] INFO [RAGChat.agent_excute:79] 3,结束调用llms,共耗时8.815192461013794
[2025-02-22 23:22:56] INFO [RAGChat.agent_excute:74] 4,开始调用llms
[2025-02-22 23:23:05] INFO [RAGChat.agent_excute:79] 4,结束调用llms,共耗时9.09904146194458
[2025-02-22 23:23:05] INFO [RAGChat.agent_excute:74] 5,开始调用llms
[2025-02-22 23:23:14] INFO [RAGChat.agent_excute:79] 5,结束调用llms,共耗时8.675729751586914
[2025-02-22 23:23:14] INFO [RAGChat.agent_excute:74] 6,开始调用llms
[2025-02-22 23:23:23] INFO [RAGChat.agent_excute:79] 6,结束调用llms,共耗时9.158662796020508
[2025-02-22 23:23:23] INFO [RAGChat.agent_excute:74] 7,开始调用llms
[2025-02-22 23:23:34] INFO [RAGChat.agent_excute:79] 7,结束调用llms,共耗时11.458032608032227
[2025-02-22 23:23:34] INFO [RAGChat.agent_excute:74] 8,开始调用llms
[2025-02-22 23:23:46] INFO [RAGChat.agent_excute:79] 8,结束调用llms,共耗时11.579402208328247
[2025-02-22 23:23:46] INFO [RAGChat.agent_excute:74] 9,开始调用llms
[2025-02-22 23:24:00] INFO [RAGChat.agent_excute:79] 9,结束调用llms,共耗时13.818564176559448
[2025-02-22 23:24:00] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 23:24:00] INFO [RAGChat.agent_excute:74] 10,开始调用llms
[2025-02-22 23:24:10] INFO [RAGChat.agent_excute:79] 10,结束调用llms,共耗时10.447782516479492
[2025-02-22 23:24:10] INFO [RAGChat.agent_excute:74] 11,开始调用llms
[2025-02-22 23:24:19] INFO [RAGChat.agent_excute:79] 11,结束调用llms,共耗时8.812650680541992
[2025-02-22 23:24:19] INFO [RAGChat.agent_excute:74] 12,开始调用llms
[2025-02-22 23:27:19] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 23:27:34] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 23:27:46] INFO [RAGChat.agent_excute:79] 1,结束调用llms,共耗时11.40343427658081
[2025-02-22 23:27:46] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 23:27:58] INFO [RAGChat.agent_excute:79] 2,结束调用llms,共耗时12.727218866348267
[2025-02-22 23:27:58] INFO [RAGChat.agent_excute:74] 3,开始调用llms
[2025-02-22 23:28:14] INFO [RAGChat.agent_excute:79] 3,结束调用llms,共耗时15.329841613769531
[2025-02-22 23:28:14] INFO [RAGChat.agent_excute:74] 4,开始调用llms
[2025-02-22 23:28:27] INFO [RAGChat.agent_excute:79] 4,结束调用llms,共耗时13.686906576156616
[2025-02-22 23:28:27] INFO [RAGChat.agent_excute:74] 5,开始调用llms
[2025-02-22 23:28:44] INFO [RAGChat.agent_excute:79] 5,结束调用llms,共耗时16.712241888046265
[2025-02-22 23:28:44] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 23:28:44] INFO [RAGChat.agent_excute:74] 6,开始调用llms
[2025-02-22 23:29:30] INFO [RAGChat.setup_logging:87] 日志系统初始化成功，日志文件: d:\deep_learning\codes\agent\logs\2025-02\ragchat_2025-02-22.log
[2025-02-22 23:29:40] INFO [RAGChat.agent_excute:74] 1,开始调用llms
[2025-02-22 23:29:48] INFO [RAGChat.agent_excute:79] 1,结束调用llms,共耗时8.466164112091064
[2025-02-22 23:29:48] INFO [RAGChat.agent_excute:74] 2,开始调用llms
[2025-02-22 23:29:55] INFO [RAGChat.agent_excute:79] 2,结束调用llms,共耗时7.122935056686401
[2025-02-22 23:29:55] INFO [RAGChat.agent_excute:74] 3,开始调用llms
[2025-02-22 23:30:03] INFO [RAGChat.agent_excute:79] 3,结束调用llms,共耗时7.671760082244873
[2025-02-22 23:30:03] INFO [RAGChat.agent_excute:74] 4,开始调用llms
[2025-02-22 23:30:13] INFO [RAGChat.agent_excute:79] 4,结束调用llms,共耗时9.825798749923706
[2025-02-22 23:30:13] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 23:30:13] INFO [RAGChat.agent_excute:74] 5,开始调用llms
[2025-02-22 23:30:27] INFO [RAGChat.agent_excute:79] 5,结束调用llms,共耗时14.268783807754517
[2025-02-22 23:30:27] INFO [RAGChat.agent_excute:74] 6,开始调用llms
[2025-02-22 23:30:37] INFO [RAGChat.agent_excute:79] 6,结束调用llms,共耗时10.176065683364868
[2025-02-22 23:30:37] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 23:30:37] INFO [RAGChat.agent_excute:74] 7,开始调用llms
[2025-02-22 23:30:50] INFO [RAGChat.agent_excute:79] 7,结束调用llms,共耗时12.820803880691528
[2025-02-22 23:30:50] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 23:30:50] INFO [RAGChat.agent_excute:74] 8,开始调用llms
[2025-02-22 23:31:02] INFO [RAGChat.agent_excute:79] 8,结束调用llms,共耗时11.7401602268219
[2025-02-22 23:31:02] ERROR [RAGChat.agent_excute:83] 调用结果出错，结果如：{},即将重试
[2025-02-22 23:31:02] INFO [RAGChat.agent_excute:74] 9,开始调用llms
[2025-02-22 23:31:10] INFO [RAGChat.agent_excute:79] 9,结束调用llms,共耗时8.520195245742798
[2025-02-22 23:31:13] INFO [RAGChat.online_search:54] online_search result:['1、《番茄工作法图解》 · 2、《奇特的一生》 · 3、《高效能人士的七个习惯》 · 4、《精力管理》 · 5、《拖延心理学》 · 6、《吃掉那只青蛙》.', '本书以7堂课的形式，系统地介绍了高效管理时间的方法，这些方法被分为目标管理、情绪管理、精力管理、日程管理、效率管理、碎片管理和外包管理。 首先，来感', '推荐一本描写混乱的书《完美的混乱》 第一次阅读5分，第二次修正为4分，这本书让我从另一个角度审视了时间管理; 还可以参考一些心智提升类书籍，特别推荐刘末', '书单 | 如何做好时间管理？强烈推荐这25本书，总有一本适合你！ - 简书 书单 | 如何做好时间管理？强烈推荐这25本书，总有一本适合你！ 书单 | 如何做好时间管理？强烈推荐这25本书，总有一本适合你！ 沈念sama阅读 213,616评论 6赞 492 沈念sama阅读 91,020评论 3赞 387 开封第一讲书人阅读 159,078评论 0赞 349 文/不坏的土叔 我叫张陵，是天一观的道长。 经常有香客问我，道长，这世上最难降的妖魔是什么？ 我笑而不... 开封第一讲书人阅读 57,040评论 1赞 285 茶点故事阅读 66,154评论 6赞 385 文/花漫 我一把揭开白布。 她就那样静静地躺着，像睡着了一般。 火红的嫁衣衬着肌肤如雪。 梳的纹丝不乱的头发上，一... 开封第一讲书人阅读 50,265评论 1赞 292 沈念sama阅读 39,298评论 3赞 412 文/苍兰香墨 我猛地睁开眼，长吁一口气：“原来是场噩梦啊……” “哼！你这毒妇竟也来了？” 一声冷哼从身侧响起，我... 开封第一讲书人阅读 38,072评论 0赞 268 沈念sama阅读 44,491评论 1赞 306 正文 独居荒郊野岭守林人离奇死亡，尸身上长有42处带血的脓包…… 初始之章·张勋 以下内容为张勋视角 年9月15日... 茶点故事阅读 36,795评论 2赞 328 正文 我和宋清朗相恋三年，在试婚纱的时候发现自己被绿了。 大学时的朋友给我发了我未婚夫和他白月光在一起吃饭的照片。... 茶点故事阅读 38,970评论 1赞 341 沈念sama阅读 34,654评论 4赞 337 正文 年R本政府宣布，位于F岛的核电站，受9级特大地震影响，放射性物质发生泄漏。R本人自食恶果不足惜，却给世界环境... 茶点故事阅读 40,272评论 3赞 318 文/蒙蒙 一、第九天 我趴在偏房一处隐蔽的房顶上张望。 院中可真热闹，春花似锦、人声如沸。这庄子的主人今日做“春日... 开封第一讲书人阅读 30,985评论 0赞 21 文/苍兰香墨 我抬头看了看天上的太阳。三九已至，却和暖如春，着一层夹袄步出监牢的瞬间，已是汗流浃背。 一阵脚步声响... 开封第一讲书人阅读 32,223评论 1赞 267 沈念sama阅读 46,815评论 2赞 365 正文 我出身青楼，却偏偏与公主长得像，于是被迫代替她去往敌国和亲。 传闻我的和亲对象是个残疾皇子，可洞房花烛夜当晚... 茶点故事阅读 43,852评论 2赞 351 公羽依娜阅读 3,530评论 17赞 158 泉水_544e阅读 215评论 0赞 0 评论25 赞20', 'GTD时间管理同主题书单，8本已读书籍梳理 · 《搞定》，[美]戴维·艾伦 · 《超级时间整理术》，迈克尔•赫佩尔 · 《时间管理》，[美] 吉姆·兰德尔 · 《奇特的一生》，[']
[2025-02-22 23:31:13] INFO [RAGChat.agent_excute:74] 10,开始调用llms
[2025-02-22 23:31:24] INFO [RAGChat.agent_excute:79] 10,结束调用llms,共耗时10.850658178329468
[2025-02-22 23:31:24] ERROR [RAGChat.agent_excute:125] agent action call error: 'gbk' codec can't encode character '\u2022' in position 118: illegal multibyte sequence
